\hlavka{ Risk-Sensitive Average Optimality in Semi-Markov Decision Processes }{ Karel Sladky }{ sladky@utia.cas.cz }{ Institute of Information Theory and Automation of the CAS, Czechia }{  }

\begin{Abstrakt}
    We consider semi-Markov reward processes evolving on finite state spaces. Attention is focused on so-called risk-sensitive models, i.e. we establish explicit formulas for the  expectation of the generated total reward measured be exponential utility function.  Using Taylor expansion we present explicit formulas for the expected reward along with its asymptotic behaviour of moments and central moments of the considered exponential utility function.  Recall that the results for risk-sensitive optimality for the classical Markov decision chains in discrete and continuous time setting turn out to be a very specific case of the considered model.
\end{Abstrakt}

\klicovaslova{
    semi-Markov reward processes, exponential utility function, formulae for central moments, long run optimality
}


\clearpage