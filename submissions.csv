ID;Author;Title;Link;Email;Keywords;Abstract;Authors
1;Diana Bílková;Welfare or Poverty of Czech Pensioners during the Energy Crisis: A Linear Regression Model;https://easychair.org/conferences/submission_view?a=32726078&submission=6782344;bilkova@vse.cz;net monthly income of the pensioner's household,welfare and poverty of pensioners,negative effect of the energy crisis,multiple linear regression,stepwise regression,sequential F-test,multicollinearity,homoscedasticity and heteroscedasticity;The paper is focused on the total net monthly income of the pensioner's household at the time of the energy crisis, which represents the explained quantitative variable in the linear regression model. This income represents one of the main characteristics of the quantitative aspect of living standards, and not only for households of senior citizens. The initial explanatory quantitative variables entering into the model are number of household members, property of the pensioner's family, number of living rooms, pensioner's age, municipality size, number of pensioner's children, age of the pensioner's partner and length of current partnership.The results of the sample survey are for the year 2022 and include only pensioners aged 65 and over. The data was provided by the Czech Statistical Office. The length of current partnership variable was removed from the model due to harmful multicollinearity. The sequential F-test showed that the most important explanatory variable is the number of household members in terms of influence on the explained variable.;Diana%Bílková%Prague University of Economics and Business%Czechia%bilkova@vse.cz
2;Jan Kalina;Some regularized tools for dimensionality reduction;https://easychair.org/conferences/submission_view?a=32726078&submission=6821686;kalina@cs.cas.cz;Dimensionality reduction,Regularization,Shrinkage,Classification,Robustness;"Dimensionality reduction has become a commonly used part of the analysis of complex economic data. The aim of this work is to study the potential or regularized tools for dimensionality reduction methods and possibly to propose some novel regularized tools. The regularization in the form of shrinkage allows to improve numerical stability of the tools for high-dimensional data and also to reduce variability of parameter estimates at the cost of introducing bias. Firstly, a robust regularized version of the coefficient of multiple correlation is proposed, which may be exploited within a Minimum Relevance Maximum Redundancy supervised variable selection. Secondly, the ridge regularization is discussed not to bring any modification of principal component analysis; this is true also for robust versions of principal component analysis.";Jan%Kalina%Charles University, Faculty of Mathematics and Physics%Czechia%kalina@cs.cas.cz
3;Radmila Krkošková;Economic Growth and Agricultural Sector Dynamics in the Visegrad Group: A Panel Analysis;https://easychair.org/conferences/submission_view?a=32726078&submission=6838189;stoklasova@opf.slu.cz;agricultural,ARDL,economic growth,food production index,panel analyse;This empirical investigation analyzes the interplay between employment in the agricultural sector, food production index, and economic growth within the Visegrad Group. Utilizing panel analysis, the study investigates annual time series data spanning from 2005 to 2023. Employing panel data analysis and the Autoregressive Distributed Lag (ARDL) model, the study aims to clarify the research objectives. Findings reveal that, in the short and long terms, the food production index significantly impacts economic growth. Specifically, an increase in the food production index correlates with boosted economic growth. Conversely, a decline in the agricultural sector labor force tends to spur economic growth.{{newline}}The agricultural sector continues to be a vital pillar of economic growth in the Visegrad Group. Understanding the dynamics, challenges, and opportunities within this sector is essential for policymakers, stakeholders, and investors to formulate strategies that promote sustainable development across the countries.;Radmila%Krkošková%Silesian University in Opava, School of Business Administration in Karviná, Department of Informatics and Mathematics%Czechia%stoklasova@opf.slu.czˇZuzana%Neničková%Silesian University in Opava, School of Business Administration in Karviná, Department of Informatics and Mathematics%Czechia%nenickova@opf.slu.czˇLucie%Waleczek Zotyková%Silesian University in Opava, School of Business Administration in Karviná, Department of Informatics and Mathematics%Czechia%waleczekzotykova@opf.slu.cz
4;Tomas Formanek;Accessibility of public charging infrastructure for electric vehicles across Central European countries: a geospatial analysis.;https://easychair.org/conferences/submission_view?a=32726078&submission=6842191;formanek@vse.cz;Electric vehicles,charging infrastructure,spatial analysis,count data model;This study models spatial distribution of electric vehicle (EV) charging stations across eight EU nations, a pivotal aspect in the decarbonization strategy of the transportation domain. Employing geolocated open source dataset, augmented with official statistical data, we conduct a quantitative analysis on a finely granulated hexagonal grid. Our findings demonstrate that zero-inflated two stage models exhibit superior performance compared to conventional Poisson count model in this specific context. Moreover, our modeling endeavors reveal that a substantial portion of the variability in the geographic dispersion of EV chargers can be explained by country-specific fixed effects and the population count of a given grid cell.;Tomas%Formanek%VSE Prague%Czechia%formanek@vse.czˇJindřich%Lacko%VSE Prague%Czechia%jindra.lacko@vse.cz
5;Tereza Chmelová;An Approach for Solving Traveling Salesman and Vehicle Routing Problems in MS Excel;https://easychair.org/conferences/submission_view?a=32726078&submission=6848075;chmt02@vse.cz;traveling salasman problem,vehicle routing problem,MS Excel solver,heterogenous fleet;This paper introduces an approach for solving Traveling Salesman Problem (TSP) and Vehicle Routing Problem (VRP) for a heterogeneous fleet of vehicles in MS Excel. MS Excel, along with its optimization solver add-in application with implemented evolutionary algorithm, was selected as the platform for development of the procedure. The evolutionary algorithm enables MS Excel to identify sub-optimal routes of the considered problems within a short timeframe. The second part of the paper presents two examples that illustrate the application of the proposed procedure for a TSP with 23 locations, and a VRP with 26 locations. All locations are situated in Prague, the capital city of the Czech Republic, and its vicinity. The results prove the effectiveness of the algorithm in optimizing route planning for urban environments, highlighting its practicality in real-world scenarios.;Tereza%Chmelová%Prague University of Economics and Business%Czechia%chmt02@vse.cz
6;Aleš Kresta;On the Dependencies between Sentiment and Assets‘ Characteristics;https://easychair.org/conferences/submission_view?a=32726078&submission=6848161;ales.kresta@vsb.cz;sentiment,stock returns,volatility,trading volume;In this empirical study, we investigate the relationships between market sentiment and the characteristics of stock returns. Our analysis focuses on the impact of the sentiment index on returns, volatility, and trading volume. The dataset under analysis comprises the components of the Standard & Poor’s 500, with adjusted close prices considered. As explanatory variables, we incorporate historical data on Fama-French factors, and as a sentiment proxy, we use the historical data of the Investors Intelligence Survey conducted by the American Association of Individual Investors and the University of Michigan Consumer Sentiment Index. GARCH models are used to measure volatility. The dependencies are assessed through linear regressions with different response variables (return, volatility, trading volume) and explanatory variables (Fama-French factors and sentiment indexes). When applicable, we also utilize the GUHA method of automatic generation of hypotheses based on empirical data. The results indicate a limited influence of sentiment on stock returns, but statistical significance in explaining trading volume. Positive sentiment leads to a decrease in trading volume, and negative sentiment leads to an increase in trading volume. These findings underscore the importance of considering investor sentiment in understanding market dynamics.;Aleš%Kresta%VSB - Technical University of Ostrava%Czechia%ales.kresta@vsb.cz
7;Qian Gao;An Empirical Efficiency Comparison of Downside Risk and Drawdown Risk in Dynamic Portfolio Optimization;https://easychair.org/conferences/submission_view?a=32726078&submission=6848380;qian.gao.st@vsb.cz;portfolio optimization,downside risk,drawdown risk,time periods;Through an in-depth exploration of risk, we have come to recognize the crucial role of downside risk in identifying potential extreme risks, and drawdown risk focuses on losses under adverse conditions. These two types of risks contribute to decision optimization, but their actual benefits within portfolios remain unclear. Consequently, this paper aims to utilize empirical data from diverse market environments, employing these two risk types to construct dynamic portfolios and conduct multi-dimensional comparisons. The chosen risk measures comprise maximum drawdown, conditional value at risk, entropic value at risk, conditional drawdown at risk, and entropic drawdown at risk. In our empirical study, we demonstrate the performance of downside risk and drawdown risk under different market conditions, comparing indicators of optimal holding periods for maximum returns across various time periods using Z-scores. The results indicate the effectiveness of risk-constructed portfolios, with drawdown risk exhibiting notable advantages. Additionally, the efficiency varies across different time periods and market conditions. This further elucidates that various markets may possess unique risk measurements tailored to their respective characteristics.;Qian%Gao%VSB-Technical University of Ostrava%Czechia%qian.gao.st@vsb.cz
8;Benjamin Emmenegger;Application of the Three-Level Aggregation Model for Evaluating Opinions Under Hesitance for Fuzzy Voting in Spatial Planning Public Decision-Making;https://easychair.org/conferences/submission_view?a=32726078&submission=6848543;benjamin.emmenegger@unifr.ch;fuzzy voting,choquet integral,spatial planning,decision making;Diverse activities, such as construction, affect the living conditions of inhabitants and their subgroups differently. Citizens should express their support and/or resistance to each alternative. Since these opinions are highly subjective, it is reasonable to use fuzzy sets to express them and reveal to what extent an opinion inclines to these opposite poles. To tackle the challenge of receiving inconsistent responses, i.e., simultaneous high levels of support and resistance for the same alternative, this paper deals with reinforcing the consistent answers and, vice versa, weakening the contradictory responses.  We consider geographical subgroups depending on the degree to which each alternative would affect them. The impact of coalitions among subgroups is explored because it does matter if, e.g., two the most affected subgroups or two lightly affected subgroups agree. Using the selected fuzzy measures, we assign weights to subgroups and their coalitions based on geographical features. Additionally, to check the robustness of the results, a careful sensitivity analysis by Monte Carlo simulation is done. In this way, we emphasise the importance of understanding the dynamics within and between these subgroups for interpreting the results. The model accentuates differences in the data and offers a clearer view of the tendencies.;Benjamin%Emmenegger%University of Fribourg, Human-IST Institute, Bd de Pérolles 90, CH-1700 Fribourg, Switzerland%Switzerland%benjamin.emmenegger@unifr.chˇMiroslav%Hudec%VSB - Technical University of Ostrava, Ostrava, Czech Republic%Czechia%miroslav.hudec@vsb.czˇEdy%Portmann%University of Fribourg, Human-IST Institute, Bd de Pérolles 90, CH-1700 Fribourg, Switzerland%Switzerland%edy.portmann@unifr.chˇGeorgiana%Bigea%University of Fribourg, Human-IST Institute, Bd de Pérolles 90, CH-1700 Fribourg, Switzerland%Romania%georgiana.bigea@unifr.chˇZapletal%Frantisek%VSB - Technical University of Ostrava, Ostrava, Czech Republic%Czechia%frantisek.zapletal@vsb.cz
9;Nikola Kaspříková;Sentiment analysis in press releases about the Czech economy by institutional stakeholders;https://easychair.org/conferences/submission_view?a=32726078&submission=6849057;nikola.kasprikova@vse.cz;text mining,sentiment analysis,polarity score,Czech economy;The paper provides a natural language processing analysis based on press releases of three established  institutional stakeholders in Czech economy who are traditionally getting coverage in Czech media. The press releases by the Czech Chamber of Commerce, Czech-Moravian Confederation of Trade Unions and by the Confederation of Industry of the Czech Republic are analysed in this paper. The aim of the paper is to learn what is the sentiment polarity in recent press releases of these institutions and if there is a major difference in sentiment between the institutions. The results of basic analysis and polarity sentiment scores are reported.{{newline}}The results of a dictionary based sentiment analysis show that all three institutions produced documents of mixed polarity within the period selected for the analysis. Most documents have positive sentiment polarity, but there were documents with negative polarity too. The Czech-Moravian Confederation of Trade Unions produced press releases with the lowest mean polarity score, but there is no major difference in sentiment polarity score in documents with respect to the institution which has produced them.;Nikola%Kaspříková%VŠE%Czechia%nikola.kasprikova@vse.cz
10;Peter Knížat;Regional Intensity of the Freight: Functional Analysis of Variance;https://easychair.org/conferences/submission_view?a=32726078&submission=6849999;peter.knizat@euba.sk;regional freight,analysis of variance,functional parameters;New digital data sources provide a great opportunity for econometrists to study the application of more complex statistical models, of which the corresponding empir-ical results can lead to prompt decision making since its early availability. In this paper, we introduce a theoretical framework of analysis of variance that is extend-ed to a functional space. An estimation procedure uses a modified method of least squares that minimizes a set of mathematical objects in its criterion. The estimated functional parameters are observed on a continuous domain rather than discrete point-wise estimates as its classical counterparts. In the empirical analysis, we use a dataset of electronic records that is collected from the satellite-based toll system in Slovakia. Each record refers to a passage of the vehicle through a section of the monitored road. We aggregate data into weekly time series, i.e. a number of pass-ing vehicles per week for each district. The weekly time series are transposed into a functional space through an expansion by basis splines. The observed mathematical objects that correspond to each district are categorized within a particular region and its co-variability is further analysed within the concept of functional analysis of variance. The main objective of the paper is to carry out the assessment of the intensity of the regional freight in Slovakia. The empirical results show various seasonal patterns of variations and significant differences of the freight between regions.;Peter%Knížat%University of Economics in Bratislava%Slovakia%peter.knizat@euba.sk
11;František Koblasa;Flexible Job Shop Scheduling with setup, transportation and planned machine idle time.;https://easychair.org/conferences/submission_view?a=32726078&submission=6852417;frantisek.koblasa@tul.cz;Flexible Job Shop Scheduling Problem,Transportation,Setup,Planned idle time,Evolution Algorithm;The Flexible Job Shop Scheduling Problem (FJSP) is one of the most popular scheduling models because of its ability to describe various real-life manufacturing systems. Despite being used mainly in its natural form, more practical constraints such as transportation and setup times have attracted attention in the last decade as setups and internal transportation are the most visible non-valued added processes.{{newline}}This article focuses on Flexible Job Shops with transport and setup times, adding planned idle times between machine operations. Those idle times depend not on job types as sequence-dependent setups but on machine type and represent regular maintenance, administration, scrap management, etc.{{newline}}This article aims to enhance the known FJSP models with setup and transportation times by idle time constraints and test the real-world approach of dispatch-ing rules against the advanced evolution algorithm technique. The basic scheduling generation technique is compared with the earliest processing job start selection.{{newline}}Together with the model, known FJSP testing instances are modified to suit the needs of the above-mentioned constraint and experiment. Generalization of testing instances modifications to real-world and combinatorial optimization needs is discussed.;František%Koblasa%Technical University of Liberec - Department of Manufacturing Systems and Automation%Czechia%frantisek.koblasa@tul.czˇMiroslav%Vavroušek%Technical University of Liberec - Department of Manufacturing Systems and Automation%Czechia%miroslav.vavrousek@tul.cz
12;Lukáš Veverka;Refining Fourier Approach with Constrained Parameter Estimation and Penalizing Seasonal Distortions;https://easychair.org/conferences/submission_view?a=32726078&submission=6852555;lukyveverka@seznam.cz;Fourier transformation,Constrained parameter estimation,Seasonal decomposition,Data-driven marketing;This study addresses the challenge of determining initial parameters in a constrained space for Fourier transformations applied to decompose time series data of media investments, focusing on identifying the underlying seasonal components at minimal levels. Recognizing that observed peaks of any business KPIs can be attributed to various external factors such as special events and media activities. The research modifies the Sum of Squared Residuals (SSR) methodology, which aims to penalize overestimations in the form of negative residuals. Thus, the distribution of residuals becomes highly skewed. The maximum likelihood method is used to get likelihood, and the Akaike information criterion (AIC) is used to evaluate the appropriate order of Fourier transformation. Based on the outputs, it is possible to provide suitable initial parameters for more complex regression models based on non-linear optimization.;Lukáš%Veverka%University of Economics in Prague%Czechia%lukyveverka@seznam.cz
13;Stanislav Letkovský;Comparative Analysis of Bankruptcy Prediction Models in Metallurgical Industry: Logistic Regression versus Artificial Intelligence Techniques;https://easychair.org/conferences/submission_view?a=32726078&submission=6853519;stanislav.letkovsky@smail.unipo.sk;bankruptcy prediction,artificial intelligence,logistic regression,Slovak metallurgical industry,financial indicators;Bankruptcy prediction becomes part of the financial manager's toolkit, enabling them to address the potential threat of bankruptcy with the aid of a suitable tool. AI is increasingly becoming a popular method in this area as well. Will this technology supplant classic logistic regression in terms of performance? This study aims to compare the prediction accuracy of LR and selected AI methods. The research is conducted on a sample of over 4,600 enterprises from the metallurgical industry in the conditions of the Slovak Republic from 2019 to 2021. This period allows for a comparison between the pre-crisis period and the period of crisis during the COVID-19 pandemic. Currently, no model focuses on this specific industry in the conditions of this country. This study offers a unique tool for identifying bankruptcy in the metallurgical industry of the Slovak Republic, which can be easily adapted to other countries with a similar underdeveloped capital market. A critical aspect of bankruptcy prediction is the selection of reliable predictors. Based on the analyzed literature, 40 financial indicators are empirically investigated. The proposed prediction models contain optimally selected indicators potentially significant in predicting bankruptcy under these conditions. All proposed models achieve high accuracy.;Stanislav%Letkovský%University of Prešov%Slovakia%stanislav.letkovsky@smail.unipo.skˇSylvia%Jenčová%University of Prešov%Slovakia%sylvia.jencova@unipo.skˇMarta%Miškufová%University of Prešov%Slovakia%marta.miskufova@unipo.skˇPetra%Vašaničová%University of Prešov%Slovakia%petra.vasanicova@unipo.sk
14;Petr Pokorný;Profit Allocation in a Multi-Echelon Closed-Loop Supply Chain: A Cooperative Game Theoretical Approach;https://easychair.org/conferences/submission_view?a=32726078&submission=6853659;petrpokorny@yahoo.ca;Closed-Loop Supply Chain,Cooperative,Game Theory,Nash Equilibrium,Core,Shapley;In this paper we consider a CLSC consisting of a manufacturer that uses both new and recycled materials to manufacture products sold by a retailer. A third collector collects the end-of-life products and sells them to the manufacturer for reprocessing. In contrast to the dominant non-cooperative research, we use the cooperative game theory approach to study the stability of the coalition structures. We start with a non-cooperative Stackelberg solution led by the producer and then form all possible coalitions. By analyzing the core and its stability conditions, we prove that the core is not empty and that the end customer can benefit from better net product prices when coalitions are formed. The fairness of the profit distribution is tested using the Shapley value and is shown to be in the core. The return rate all increases under the cooperative approach, with one exception when the third party collector is not part of any coalition.;Petr%Pokorný%Prague University of Economics and Business%Czechia%petrpokorny@yahoo.ca
15;Tereza Čapková;Portfolio Analysis: Exploring Rank Length Metrics;https://easychair.org/conferences/submission_view?a=32726078&submission=6853665;capkot00@jcu.cz;Portfolio Performance,GET package,ERL,CRL,Extreme Rank Length,Continuous Rank Length,Financial Management,Financial Analysis;Portfolio analysis is a crucial aspect of financial management, with numerous specialists continually seeking to develop novel approaches that may enhance decision-making methods. This study investigates the application of Extreme Rank Length (ERL) and Continuous Rank Length (CRL) metrics as alternative approaches for assessing portfolios, deviating from traditional optimization methods. The motivation for this work stems from the robustness of stochastic dominance. To determine the effectiveness of ERL and CRL in evaluating portfolios, we simulate portfolios using the eleven most active stocks by dollar volume. The performance of these portfolios is evaluated using ERL and CRL metrics. Our research opens the door for further investigation and development in financial analysis by highlighting the potential of these metrics in portfolio evaluation.;Tereza%Čapková%University of South Bohemia, Faculty of Economics%Czechia%capkot00@jcu.cz
16;Kevin Nowag;Efficiency analysis of grass seed multiplication in Germany: A case study of the leading Company;https://easychair.org/conferences/submission_view?a=32726078&submission=6853719;xnowag@node.mendelu.cz;Efficiency analysis,Data envelopment analysis,Multiplication of grasses,Seed business,Agriculture;In the past, multiplication was mainly focused on quality. Global political events have made market prices for competing agricultural products much more volatile and put prices in the multiplication sector under considerable pressure. This has brought the efficiency of multiplication much more into focus.{{newline}}Data envelopment analysis is used for the efficiency analysis. The aim of the study is to compare the yields achieved with the help of basic potentials of the farmers with regard to soil fertility and weather data. In the next step of the analysis, the DEA results are used to perform a regression with specific parameters of the contract farmers. The analysis of the results should make it possible to characterize contract farmers and enable the seed company to increase efficiency by selecting farmers differently.{{newline}}The data for the DEA are GPS coordinates of the investigated fields, weather data from the German weather service and the Müncheberger Soil Quality Rating was used for the potential of the soil. The yield achieved per field was scaled using the average multi-year yield of the specific variety in order to be able to compare the complete data.;Kevin%Nowag%PhD Student Mendel University%Germany%xnowag@node.mendelu.cz
17;Martin Dlouhý;Failures in the evaluation of the health system efficiency by data envelopment analysis;https://easychair.org/conferences/submission_view?a=32726078&submission=6853787;dlouhy@vse.cz;data envelopment analysis,health system,health;Data envelopment analysis is a popular quantitative method of relative efficiency evaluation of health systems. However, such efficiency evaluation has to deal with many pitfalls that result from the fact that the production of health differs from the traditional theory of production as we know it from economic textbooks. The definition of production output (health) is problematic, as it is unclear how to measure population health. Other pitfalls are related to health being affected by factors outside the health system. The causal relationship between inputs and outputs is complicated and uncertain. We also need to assume that the health systems are homogeneous production units.;Martin%Dlouhý%Prague University of Economics and Business%Czechia%dlouhy@vse.cz
18;Michaela Tichá;A Coalition Formation as a Multicriteria Voting Game;https://easychair.org/conferences/submission_view?a=32726078&submission=6853867;Michaela.Ticha@ujep.cz;game theory,multicriteria voting game,coalition stability,political power dynamics;In the multicriteria voting game, we assume a set of political parties and a set of po-litical programs with multiple dimensions of public policy. The coalition program is formulated as a weighted average of the individual political programs. The objec-tive of each political party is to minimize the maximum distance between the coali-tion program and its own program, to maximize its own share of power in the win-ning coalition, and to maximize the stability of the winning coalition, which is measured as the maximum distance between the coalition program and the indi-vidual programs of all political parties in the coalition. The multicriteria voting game model is applied to the Chamber of Deputies of the Parliament of the Czech Repub-lic. Deputies were surveyed using a questionnaire that included 16 key questions. For each question, deputies selected from five scaled responses. The data obtained was used to calculate the optimal winning coalition.;Michaela%Tichá%Jan Evangelista Purkyně University%Czechia%Michaela.Ticha@ujep.czˇMartin%Dlouhý%Prague University of Economics and Business%Czechia%dlouhy@vse.cz
19;Vladimír Holý;Analyzing Determinants of Success in Ice Hockey World Championships;https://easychair.org/conferences/submission_view?a=32726078&submission=6854038;vladimir.holy@vse.cz;Ice Hockey Rankings,Generalized Autoregressive Score Model,Plackett–Luce Distribution;The study examines the determinants of team success in the Ice Hockey World Championships. The annual final rankings are analyzed through a dynamic model utilizing the Plackett–Luce distribution with time-varying worth parameters driven by the conditional score, i.e. the gradient of the log-likelihood. Various exogenous variables are incorporated to address key questions: Does the host team enjoy a home advantage? Does the success of junior teams correlate with increased prospects of winning the main tournament in subsequent years? Are teams more advantaged by youthful talent or seasoned players? Furthermore, the study investigates which game statistics hold the most significance for accurate forecasting.;Vladimír%Holý%Prague University of Economics and Business%Czechia%vladimir.holy@vse.cz
20;Oleh Kurinnyi;From Petrochemicals to Produce: Unveiling the Fertilizer-Crude Oil Nexus;https://easychair.org/conferences/submission_view?a=32726078&submission=6854286;kuro01@vse.cz;NARDL,rockets-and-feathers effect,breakpoints,asymmetric;The study explores the intricate relationship between crude oil and global fertilizer prices, highlighting fertilizer's significant role in food commodity costs. While prior research has emphasized crude oil's impact, this study unveils the extensive economic and social repercussions of fertilizer market shocks. Investigating potential asymmetric price transmission, the study employs a Nonlinear Autoregressive Distributed Lag (NARDL) model to analyze the nonlinear dynamics between spot prices of various fertilizers and crude oil. By utilizing the Bai-Perron method to identify structural changes, the study unveils both symmetric and asymmetric responses in fertilizer prices over different time periods, underscoring the dynamic nature of this crucial relationship.;Oleh%Kurinnyi%Prague University of Economics and Business%Czechia%kuro01@vse.czˇLukáš%Frýd%Prague University of Economics and Business%Czechia%lukas.fryd@vse.cz
21;Lukáš Frýd;Asymmetries in Savings-Investment Nexus: Global Perspectives;https://easychair.org/conferences/submission_view?a=32726078&submission=6854301;lukas.fryd@vse.cz;quantile regression,common latent factors,saving-investment nexus,asymmetries;This study investigates the intricate dynamics between savings and investment, focusing on potential asymmetries and heterogeneous effects across different investment quantiles in both Large and Non-Large economies. Building upon empirical evidence, we explore whether the relationship between savings and investment varies according to economic conditions, particularly during the growth or decline phases. In contrast to the symmetric effects commonly assumed, our analysis unveils significant asymmetries in the impact of savings shocks on investment changes, notably observing stronger connections for adverse shocks compared to positive ones. Moreover, we identify variations in this relationship across different investment quantiles and distinguish between the responses of Large and Non-Large economies. Specifically, adverse savings shocks demonstrate stronger associations with investment changes during periods of economic downturn or decapitalization, while positive shocks exhibit heightened effects during growth phases. These findings underscore the importance of recognizing asymmetries and quantile-specific effects, providing a nuanced understanding of the interplay between savings and investment dynamics.;Lukáš%Frýd%Prague University of Economics and Business%Czechia%lukas.fryd@vse.cz
22;Ondřej Novák;Level of efficiency of the energy industry in EU countries;https://easychair.org/conferences/submission_view?a=32726078&submission=6854302;xnovak.ondrej@gmail.com;accounting data,company,data envelopment analysis,efficiency;This article compares the efficiency of companies in the energy sector in EU coun-tries. The efficiency calculation is performed through data envelopment analysis method. The dataset includes accounting data (annual frequency) for a total of 3893 companies. The output variables represent the turnover of the company and also the net income of the company. The inputs include variables representing the capital factor and the labor factor.{{newline}}Empirical results show that the efficiency of this sector in EU countries is at a rela-tively high level (the average is around 75%). Countries such as Italy and Bulgaria have a significant share of efficient companies. Denmark, on the other hand, has the least. According to the average (and median values), companies in Estonia and Denmark performed very well. Both of these countries have a high share of renew-able energy, which may have had a positive impact on their performance.;Ondřej%Novák%Mendel University in Brno%Czechia%xnovak.ondrej@gmail.comˇVeronika%Blašková%Mendel University in Brno%Czechia%veronika.blaskova@mendelu.cz
23;Ondřej Novák;Level of efficiency of the tertiary education sector in the EU;https://easychair.org/conferences/submission_view?a=32726078&submission=6854327;xnovak.ondrej@gmail.com;data envelopment analysis,education,EU countries,efficiency;Despite the common legislative framework of the European Union, there are differ-ences in the education system among its members. Given that education is funded from public budgets, it should be monitored whether these funds are used efficient-ly. Using a non-parametric method of data envelopment analysis, we evaluate the tertiary education systems of EU countries based on the number of graduates with respect to the inputs used. In addition to the staff, we have also included public re-sources (namely R&D expenditure and public expenditure on tertiary education) as inputs. Empirical results show that some developed countries (such as Germany and Austria) do not have an efficient education system. Ireland, on the other hand, was among the top countries due to the high number of graduates relative to the inputs used.;Ondřej%Novák%Mendel University in Brno%Czechia%xnovak.ondrej@gmail.comˇMichaela%Staňková%Mendel University in Brno%Czechia%michaela.stankova@mendelu.cz
24;Michael Michael Kejmar;A Panel Analysis of the Economic Determinants of Military Spending ;https://easychair.org/conferences/submission_view?a=32726078&submission=6854512;michael.kejmar@unob.cz;GMM model,Economic Determinants,Military Spending;The development of military spending in NATO countries is characterised by an increase in military spending caused mainly by the changing security situation in Europe. The security situation and the economic environment are considered as factors (determinants) influencing the size of military spending. The aim of the article is to present the possible use of the Dynamic Panel Data model (GMM) to identify military spending determinants of selected NATO countries. To analyse the determinants of military spending of 23 countries, the following economic variables describing the economic, fiscal development of a country were selected: the size of government expenditures, the size of the government budget surplus (deficit), the size of the country's indebtedness, the economic development measured by GDP, and the size of government revenues. The results of the Dynamic Panel Data model  confirm the positive effect of government surplus, government expenditures on military spending and negative effect of government debt on military spending. The results of the model confirm the expected hypotheses about the impact of selected economic variables on the military spending of 23 NATO countries in the period 1996-2002.;Michael%Michael Kejmar%University of Defence%Czechia%michael.kejmar@unob.czˇJiří%Neubauer%University of Defence%Czechia%jiri.neubauer@unob.czˇJakub%Odehnal%University of Defence%Czechia%jakub.odehnal@unob.cz
25;Robert Hlavatý;Designing optimal transportation patterns for radiation incident recovery;https://easychair.org/conferences/submission_view?a=32726078&submission=6854613;hlavaty85@gmail.com;dose rate,linear optimization,nuclear power plant,radiation incident,routing problem,waste;In case of a radiation accident in a nuclear power plant (NPP), there is a possibility of radionuclide releases that would affect the vicinity of the NPP. Such an event subsequently requires responsible authorities to decontaminate the affected areas and remove the produced contaminated waste to the designated interim storage sites. Given the extent of the incident, the recovery of the areas may turn into long-term logistic operation involving considerable machinery and personnel. We propose an optimal routing methodology to approach this situation and employ linear optimization to deliver an effective solution to the problem. This specific routing problem is constrained not only by the vehicle capacities but also by the doses the personnel can take during the process. We seek a solution that minimizes the distance travelled by vehicles and, thus, the time for which the personnel is exposed to radiation. The presented methodology is based on the real-world measures that would be taken in case of such an incident. The model results would allow the authorities to plan sufficient vehicle and personnel availability, estimate the time needed to clear contaminated areas and estimate the capacity of the interim storage sites. We demonstrate our methodology on a small example.;Robert%Hlavatý%CZU Prague%Czechia%hlavaty85@gmail.comˇHelena%Brožová%CZU Prague%Czechia%brozova@pef.czu.czˇAnna%Selivanova%CZU Prague%Czechia%selivanova@pef.czu.czˇTereza%Sedlářová Nehézová%CZU Prague%Czechia%nehezova@pef.czu.cz
26;Eva Štichhauerová;Application of conventional DEA and ZSG-DEA models in university budget allocation;https://easychair.org/conferences/submission_view?a=32726078&submission=6854851;eva.stichhauerova@tul.cz;Budget allocation,Data Envelopment Analysis,zero-sum gains DEA model,Andersen and Petersen super-efficiency model;This paper investigates the feasibility of applying two Data Envelopment Analysis (DEA) models in allocating budgets among departments in a university. The paper is divided into three parts. The first part describes the existing methodology of budget allocation in a selected faculty of a given university. Then, two DEA models that have been used in alternative budget construction are characterized. The first model is based on the classical CCR model, supplemented by the super-effectiveness model of Andersen and Petersen. The model redistributes resources from inefficient units towards efficient units, depending on the degree of their super-efficiency. The reallocation takes place until all units are efficient. The second model is based on the zero-sum gains (ZSG) approach, where the sum of the resources of all units remains constant. Thus, the sum of the improvement and the worsening of all units under study must remain equal to zero. The last part of the paper compares the current budget allocation with alternative options under the classical and ZSG-DEA models.;Eva%Štichhauerová%Technical University of Liberec%Czechia%eva.stichhauerova@tul.czˇMiroslav%Žižka%Technická univerzita v Liberci%Czechia%miroslav.zizka@tul.cz
27;Jaromír Zahrádka;The Problem of Optimal Delivery of Frozen and Chilled Goods with given priority from Multiple Warehouses;https://easychair.org/conferences/submission_view?a=32726078&submission=6854901;jaromir.zahradka@upce.cz;Goods,Matlab,Mixed integer linear programming,Optimization,Priority,Truck routing problem;This article comes up with a specific example of the truck routing problem. The selling company has to deliver the ordered frozen or chilled goods from m warehouses to n customers as efficiently as possible. Each customer has ordered goods stored in a certain number of containers which need to be transported. All customer points of delivery and warehouse points are given by GPS coordinates. The objective of the solution is to select the number of vehicles and their routes between suitable warehouse and customers in such a way that the total travel distance or travel time is as short as possible. The order of customers on each route respects the priority of delivery of frozen goods over chilled ones. This means that chilled goods are unloaded from the truck only after all frozen goods have been unloaded at previous customer delivery points. Each of these delivery points is visited only once by one of the vehicles. In each warehouse, the same number of trucks ends the journey as they left. All trucks have the same pre-limited capacity of containers. In this article, the algorithm of the truck routing problem with multiple warehouses and priority of de-livery of frozen goods was created and implemented in Matlab code.;Jaromír%Zahrádka%University of Pardubice%Czechia%jaromir.zahradka@upce.cz
28;Jialei Xiong;Exploring Market Attention's Impact on Portfolio Optimization;https://easychair.org/conferences/submission_view?a=32726078&submission=6854987;jialei.xiong@vsb.cz;Market attention,Google Trends,Time series analysis,Portfolio optimization,Rolling window;This study explores in depth the intricate relationship between market attention and portfolio optimization. Employing a rolling window methodology, we extract Google Trends time series data for selected stocks, utilizing it as a proxy for market attention. This market attention indicator is then integrated into a suitable Google Trends model. With this model, the market attention directed towards a stock is effectively translated into corresponding weights for portfolio optimization. Our comparative analysis shows the results of traditional portfolio optimization side-by-side with the results of market attention enhancement. The findings suggest that combining market attention with portfolio optimization can significantly enhance portfolio selection strategies. This study helps to further validate the constructive impact of market focus on portfolio optimization.;Jialei%Xiong%Technical university of Ostrava%Czechia%jialei.xiong@vsb.cz
29;Blanka Bazsova;Analysis of traffic accidents and weather in the Czech republic ;https://easychair.org/conferences/submission_view?a=32726078&submission=6855000;blanka.bazsova@vsb.cz;corellation analysis,regression analysis,traffic accidents,weather;Many factors affect a traffic accident. It can be people's moods, overwork, inattention, alcohol, excessive speed, and the weather. Since the latter factor has been changing a lot recently in connection with climate change, it is necessary to determine whether these general assumptions exist and affect the accident rate positively or negatively. The theoretical assumption is that these climate changes are related to temperature fluctuations in the Czech Republic in summer and winter. We are increasingly experiencing more tropical nights and, conversely, very icy days and freezing spring, sweltering summer and virtually snowless winter. These factors associated with temperature fluctuations and the number of rainfall events are gaining importance. They are worth looking at in terms of their monthly evolution over the past seven years. This article examines the weather and accident rate in the Czech Republic. A model uses standard accident rate variables (death, serious and minor injuries or material damage) and weather-specific variables. More precisely, the investigated econometric model thus includes the mentioned standard variables and average temperature and precipitation. The relevant model is examined and tested using correlation and regression analysis and their assumptions. Moreover, based on a detailed analysis, the dependence between the accident rate and the weather is proven, and it can be seen that the change in weather generally affects the accident rate positively.;Blanka%Bazsova%VSB – Technical University of Ostrava%Czechia%blanka.bazsova@vsb.czˇLucie%Chytilova%VSB – Technical University of Ostrava%Czechia%lucie.chytilova@vsb.cz
30;Martina Hedvicakova;Analysis of Labor-Capital Substitution in Industry 4.0 Using the Cobb-Douglas Model: Strategic Decision-Making in Human Resources and Technological Investments;https://easychair.org/conferences/submission_view?a=32726078&submission=6855008;martina.hedvicakova@uhk.cz;Cobb-Douglas Production Function,Industry 4.0,Labor,Technology,Method of Least Squares,Manufacturing Industry;The article aims to create a Cobb-Douglas production function for the manufacturing industry, both for the entire industry and for individual sectors. First, a correlation analysis will be performed, then the Cobb-Douglas production function will be constructed, and the relevant coefficients will be calculated using the least squares method. The degree of determination will then be verified for the entire model. The process will be carried out for individual manufacturing industry sectors in the next part. The different degrees of determination will be discussed in individual sectors and the whole.;Martina%Hedvicakova%Univerzity of Hradec Kralove%Czechia%martina.hedvicakova@uhk.czˇMartin%Pozdílek%University of Pardubice%Czechia%martin.pozdilek@upce.czˇAlena%Pozdílková%University o Pardubice%Czechia%alena.pozdilkova@uhk.cz
31;Markéta Šindlerová;Exploring Fuzzy Functional Dependencies in Assessing Relationships between Criteria in EU ETS impacts;https://easychair.org/conferences/submission_view?a=32726078&submission=6855018;marketa.sindlerova@vsb.cz;Fuzzy Functional Dependencies,EU ETS (Emissions trading system),Interactions between Economic and Environmental Criteria;Emissions trading systems (ETS) have emerged as a crucial policy tool for tackling climate change by putting a price on carbon emissions. However, understanding the complex relations between environmental and economic criteria remains a challenge. This study explores the possibilities of fuzzy functional dependencies as a method to model the relationships between various criteria involved in assessing the effectiveness and efficiency of emissions trading schemes and the economic impacts of emissions trading within the EU ETS framework. By employing fuzzy functional dependencies, the analysis captures and explains the inherent uncertainty and vagueness in the relationships between environmental and economic variables within the EU ETS context. Finally, the article compares recognised relations among criteria by statistical methods.;Markéta%Šindlerová%VSB - TUO%Czechia%marketa.sindlerova@vsb.czˇMiroslav%Hudec%VSB - TUO%Czechia%miroslav.hudec@vsb.cz
32;Jana Junová;Almost Stochastic Dominance Analysis of Mean-Variance Efficient Portfolios;https://easychair.org/conferences/submission_view?a=32726078&submission=6855037;junova@karlin.mff.cuni.cz;stochastic dominance,almost stochastic dominance,portfolio optimization;Stochastic dominance is a tool that allows the comparison of random variables, representing the random returns of investments under very general assumptions. However, the generality of these assumptions can lead to situations where dominance between two random variables does not exist, even though the majority of investors evidently prefer one. For this reason, a relaxation of stochastic dominance called almost stochastic dominance was introduced. While the definition of almost first-order stochastic dominance is widely accepted, the definitions of almost second-order stochastic dominance (ASSD) vary.{{newline}}This article aims to describe the different approaches to ASSD and analyze the relationships between them. Using data regarding the monthly returns of 49 industry representative portfolios, we find the mean-variance efficient portfolios and analyze their ASSD relationship to the minimum variance portfolio, employing and comparing different definitions of ASSD.;Jana%Junová%Charles University%Czechia%junova@karlin.mff.cuni.czˇMiloš%Kopa%Charles University%Czechia%kopa@karlin.mff.cuni.cz
33;Richard Kovárník;The relationship between investment in machinery, employment, and output of forestry in Switzerland;https://easychair.org/conferences/submission_view?a=32726078&submission=6855585;xkovarn1@mendelu.cz;vector autoregression,Granger causality,impulse-response,forestry;This article deals with time series modelling in the field of forest management. Specifically, it is a time series containing information on investments in machinery and equipment, a time series on the number of work units and a time series on the output of the forestry sector. The data comes from the period between 1992 and 2022 in Switzerland. For this purpose, a vector autoregression model was estimated to model the dynamics between these variables, Granger causality was tested to determine interrelationships and causalities and Impulse-response analysis was performed to understand how quickly and significantly variables respond to shocks. The results obtained indicate that sudden changes in forestry output stimulate additional investment in the following year to meet the increased demand for logging and wood processing. Furthermore, the results indicate that investments in machinery and equipment affect the number of working units. In this direction, there is a decrease in working units if there were additional investments in machinery and equipment in the previous period.;Richard%Kovárník%Mendel University in Brno, Faculty of Business and Economics, Department of Statistics and Operation Analysis%Czechia%xkovarn1@mendelu.cz
34;Šárka Čížková;The Influence of the Global Recession of 2008 on Organic Food Consumption;https://easychair.org/conferences/submission_view?a=32726078&submission=6855632;cizeko@vse.cz;organic food,consumption function,income,economic crisis,error correction model;The goal of the study is to analyze how the 2008 global economic crisis affected the consumption of organic food in the Czech Republic. The study is designed to explore overall consumption attitudes. Its objective is to measure the influence of certain macroeconomic indicators, particularly income-related ones, on general consumption of organic food. Additionally, it aims to analyze how this impact evolved before and after the 2008 crisis. From a methodological point of view, the error correction methodology (ECM) is implemented, albeit with modifications to integrate breakpoint analysis for modeling the effects of the global economic crisis on organic food consumption. The econometric analysis of the estimated model confirmed a statistically significant positive dependence between organic food consumption indicators and all examined income-related indicators before 2008. However, it is also showed that this dependence ceased to exist following the global economic recession in 2008. This retrospective examination offers valuable insights into the dynamics of organic food consumption shifts triggered by economic downturns.;Šárka%Čížková%University of Economics, Prague%Czechia%cizeko@vse.cz
35;Lukáš Malec;Applying the FIML dynamic structural model in tourism industry;https://easychair.org/conferences/submission_view?a=32726078&submission=6855725;lukas.malec@vse.cz;Dynamic latent systems,structural equations,tourism;Even though the standard approaches of structural techniques can offer pseudo-maximum likelihood estimates in time series data, better criteria are needed under current technological development. The dynamic structural equation model (DSEM) used in this study originates from Ciraki, D. (2007): Dynamic structural equation model, Estimation and inference. This procedure enables the lagged latent endogenous as well as exogenous variables to arrive at a solution in one process, together with variances of model errors. We constructed one variance-covariance matrix for the entire vectorized dataset, and the likelihood is then evaluated for a single observation. Because such matrices generally suffer from numerical problems, regularization has been introduced. The initial evaluation using the 3SLS approach based on stationary methodology and identification are both performed in the observed form. Despite the indisputable advantages of the method, computational difficulty is probably the reason for the full dynamic system not yet being incorporated into econometric packages.;Lukáš%Malec%Prague University of Economics and Business, Prague, Czech Republic%Czechia%lukas.malec@vse.cz
36;Imma Lory Aprea;A neural network-particle swarm solver for sustainable portfolio optimization problems;https://easychair.org/conferences/submission_view?a=32726078&submission=6856945;immalory.aprea@uniparthenope.it;Particle Swarm Optimizer,Neural Networks,Sustainable portfolios,Constrained Optimization Problems;"In this talk, we present sustainable portfolio optimization problems in which we aim to maximize a refinement to the Sharpe Ratio measure and to minimize a systemic risk measure. More specifically, we first consider the Modified Sharpe Ratio: it corresponds to the standard Sharpe Ratio when the excess rate of return is positive; while it is adjusted by multiplying the previous quantity by the standard deviation, if such an excess rate of return is negative. Furthermore, the considered systemic risk measure is represented by the Delta Conditional Value at Risk, a tail-dependence measure meant to quantify the potential losses of a portfolio due to the riskiness associated with an individual asset. In addition, in the optimization problem, we take into account two types of real-world trading constraints. On the one hand, we impose stock market restrictions through buy-in thresholds and budget constraints. On the other hand, a turnover threshold restricts the total amount of trades allowed in the rebalancing phases. Finally, in order to meet the growing appetite for sustainable investments, we impose a green threshold into the portfolio’s construction. To deal with these asset allocation models, we embed a suitable hybrid constraint-handling procedure into an improved Particle Swarm Optimizer (PSO) that is dynamically adjusted by a neural network architecture. It is worth noting that implementing the neural network paradigm is fundamental for enhancing the PSO’s performance and improving the quality of estimating the Modified Sharpe Ratio and Delta Conditional Value at Risk measures. Finally, we conduct empirical tests on different data sets to illustrate the effectiveness of the proposed strategies and evaluate the performance of our investments as the sustainable preferences vary.";"Imma Lory%Aprea%University of Naples ""Parthenope""%Italy%immalory.aprea@uniparthenope.itˇGabriele%Sbaiz%University of Trieste%Italy%gabriele.sbaiz@deams.units.it"
37;Karel Sladky;Risk-Sensitive Average Optimality in Semi-Markov Decision Processes;https://easychair.org/conferences/submission_view?a=32726078&submission=6857056;sladky@utia.cas.cz;semi-Markov reward processes,exponential utility function,formulae for central moments,long run optimality;We consider semi-Markov reward processes evolving on finite state spaces. Attention is focused on so-called risk-sensitive models, i.e. we establish explicit formulas for the  expectation of the generated total reward measured be exponential utility function.  Using Taylor expansion we present explicit formulas for the expected reward along with its asymptotic behaviour of moments and central moments of the considered exponential utility function.  Recall that the results for risk-sensitive optimality for the classical Markov decision chains in discrete and continuous time setting turn out to be a very specific case of the considered model.;Karel%Sladky%Institute of Information Theory and Automation of the CAS%Czechia%sladky@utia.cas.cz
38;Martin Flegl;Assessing tourism efficiency in traditional beach touristic centers in Mexico: Application of dynamic two-stage DEA model and fuzzy time series forecasting;https://easychair.org/conferences/submission_view?a=32726078&submission=6857105;martin.flegl@tec.mx;Data Envelopment Analysis,Fuzzy logic,Mexico,Tourism,Window Analysis;Tourism is one of the most important economic sectors in Mexico, because it has positioned itself as one of the main tourist destinations internationally and has promoted national, regional, and local development. In other words, the participation of the tourism sector went from contributing 6.9% in 2020 to 7.6% in 2021 of the Gross Domestic Product (GDP) at current prices. The arrival of national and international tourists to Mexico has been constantly growing during the last two decades. In 2022, Mexico registered arrival of 38.326 million of international tourists, ranking the country as the 6th most visited in the world. Constant growth of tourists arrivals resulted in a direct growth of a hospitality capacity across the country. At the end of 2022, Mexico offered 881,022 hotel rooms, representing 14.55% bigger capacity compared to 2016. Such a growth creates imminent pressure to guarantee efficiency in the whole tourism sector.{{newline}}To assess the tourism efficiency in Mexico, we used the Data Envelopment Analysis, one of the most used methodologies for measuring efficiency and performance. We constructed a two-stage dynamic DEA model using monthly data for seven traditional beach touristic centers for a period 2015-2021. Stage 1 evaluates the hospitality efficiency considering hotels capacity and tourists arrival, whereas Stage 2 focuses on museums and archeological zones visits efficiency taking into account locations’ attractivity. Further, we combined the obtained efficiency results with fuzzy time series forecasting to expose a future efficiency trend in each traditional beach touristic center.;Martin%Flegl%School of Engineering and Sciences, Tecnologico de Monterrey%Mexico%martin.flegl@tec.mxˇCarmen%Lozano%Facultad de Turismo y Gastronomía, Universidad Anáhuac México%Mexico%mcarmen.lozano@anahuac.mxˇPatrick Joaquín%Cruz%School of Engineering and Sciences, Tecnologico de Monterrey%Mexico%a01027636@tec.mxˇMarketa%Matulova%Faculty of Business and Economics, Mendel University%Czechia%marketa.matulova@mendelu.cz
39;Adam Borovička;Asset return as a vague element in investment portfolio selection: fuzzy mathematical modelling;https://easychair.org/conferences/submission_view?a=32726078&submission=6857209;adam.borovicka@vse.cz;fuzzy return,mutual fund,portfolio selection,triangular fuzzy number;The return, or its level, is often an unstable, or uncertain aspect of the intended investment. It can be expressed deterministically (e.g. by a mean) or stochastically (as a random variable with a particular probability distribution). The first option loses some valuable information. The second option can complicate subsequent, particularly computational, tasks when expressing a random process explicitly. Another possibility is to use the apparatus of fuzzy set theory. Return as a (triangular) fuzzy number – fuzzy return – can adequately quantify the uncertainty associated with its expected value. The triangular form offers several particular computational advantages. Their eventual comparison also proceeds more easily. Thus, processing such fuzzy information with a mathematical model for the selection of an investment portfolio need not be difficult. However, a crucial issue is the determination of the three parameters of the fuzzy number, which is sometimes neglected in papers on this topic, although it can logically significantly affect the result. The application power of the fuzzy return concept integrated into the mathematical programming model is demonstrated through a case study of ESG mutual fund portfolio selection.;Adam%Borovička%Prague University of Economics and Business%Czechia%adam.borovicka@vse.cz
40;Petr Chládek;Simulation and strategy for the Secretary problem with cardinal function based on job specifications;https://easychair.org/conferences/submission_view?a=32726078&submission=6857356;chladek@ef.jcu.cz;Secretary problem,Hiring strategy,Cardinal utility function,Decision-making in management;"The classical Secretary problem is an applied mathematical model for choosing the best applicant from a sample of a given size; the decider can not return to an already rejected candidate and does not a priori know the scale of quality of the candidates. In this well-known problem with a given number of data with unknown distributions, we should stop the search once we consider a number to be the highest one. We opt for the original motivation, but rather than attempting to choose the best one and fail in most cases, we suggest a strategy to control the mean value of the chosen one. The utility of the candidates in different experiments is designed based on the theoretic distribution for specific job titles; we use a cardinal function with the argument being the candidate's percentile among the population. Based on the experiment, we present strategies for hiring for different roles and reveal that the strategy has to be specific for a job; otherwise, it could be suboptimal. Our strategies are based on two parameters: the size of the sample part we examine and reject at the beginning of the search and the percentile from the examined sample we demand the candidate to outperform to be accepted. We simulate all possibilities of ordering 12 candidates and evaluate the strategies based on the experiment.";Petr%Chládek%University of South Bohemia in České Budějovice/Faculty of Economics, Department of Applied Mathematics and Informatics%Czechia%chladek@ef.jcu.czˇMarika%Hrubešová%University of South Bohemia in České Budějovice/Faculty of Education, Department of Mathematics%Czechia%mhrubesova@jcu.czˇŠtěpán%Mudra%Centre of Information Technologies, Branišovská 31a, CZ - 371 15, České Budějovice, Czech Republic%Czechia%smudra@jcu.czˇMartin%Polívka%University of West Bohemia/Faculty of Economics, Department of Finance and Accounting%Czechia%polivkam@fek.zcu.czˇTomáš%Roskovec%University of South Bohemia in České Budějovice/Faculty of Education, Department of Mathematics%Czechia%troskovec@jcu.cz
41;Andrea Galadíková;Using of the simulated annealing in the decision support system of the railway transport nodes;https://easychair.org/conferences/submission_view?a=32726078&submission=6858055;andrea.galadikova@fri.uniza.sk;simulated annealing,railway,decision support;Rail transportation is an important part of ensuring the transport of people and goods. Among many other requirements, it is important to take care of the maintenance of each train set to ensure smooth operation. This maintenance is carried out in the maintenance depot. Due to the large number of different maintenance activities that need to be carried out on the train sets, but especially due to the limitations associated with the nature of train traffic (mainly movement on rails), it is important to deal with the optimization of individual processes. This is particularly challenging at the operational level, where many unexpected influences enter the planned schedules. Based on previous research dealing with the possibilities of the supporting operational management, in this article we deal with the application of the heuristic method of the simulated annealing to the selected task of assigning the sequence of the individual maintenance activities. This approach was used as part of a decision support system and was validated by a simulation model of a selected maintenance depot.;Andrea%Galadíková%Faculty of Management Science and Informatics, University of Žilina%Slovakia%andrea.galadikova@fri.uniza.skˇMarek%Kvet%Faculty of Management Science and Informatics, University of Žilina%Slovakia%marek.kvet@fri.uniza.skˇMaroš%Janovec%Faculty of Management Science and Informatics, University of Žilina%Slovakia%maros.janovec@fri.uniza.sk
42;Jan Bartoška;Extension of Planning Poker by Work Contour Models in Project Management;https://easychair.org/conferences/submission_view?a=32726078&submission=6858734;bartoska@pef.czu.cz;Project management,Agile approach,Planning Poker,Work Contour,Work Effort,Resource Allocation,Scrum;"The paper describes an extension of Scrum Planning Poker with Work Contour Model . Planning Poker is used by the agile team to determine the difficulty of tasks without determining the work effort in tasks. Work effort variability affects the team: As it increases, team member cooperation and proactivity decreases and agile principles may be compromised in the team. The authors of the paper propose adding another characteristic to the planning poker based on work effort models. The proposal builds on previous research by one of the authors on quantifying Student's syndrome and work contours of work effort, with using these modifications for Earned Value Management. Labeling tasks on Kanban Board with new characteristics added to the Planning Poker may affect cooperation on tasks during Scrum. Tasks marked as ""last-minute work"" should have higher priority for team collaboration. The paper includes a case study for use in practice and proposes a new concept of the mathematical model for work contours and work effort in agile teams. The proposed concept extends the Planning Poker and enhances adherence to the agile principles in the team.";Jan%Bartoška%Czech University of Life Sciences Prague, Department of Systems Engineering%Czechia%bartoska@pef.czu.czˇJosef%Kunhart%Czech University of Life Sciences Prague, Department of Systems Engineering%Czechia%kunhart@pef.czu.czˇJiří%Pilný%Czech University of Life Sciences Prague, Department of Systems Engineering%Czechia%pilnyj@pef.czu.cz
43;Jana Heckenbergerova;Critical Managerial Decision Making and Matrix Games;https://easychair.org/conferences/submission_view?a=32726078&submission=6859904;jana.heckenbergerova@upce.cz;conflict situation,decision making,optimization,matrix game,linear programming;A key part of a manager's job is to find the optimal solution. This can be difficult task without knowledge of advanced methods, data analysis, or evaluating the suitability of strategies. In these decision-making processes, game theory tools can be successfully used. In conflict situations, the optimal choice of strategy can lead to a win-win situation, i.e. to satisfaction on both sides. While game solutions in the field of pure strategies can be found using Nash equilibrium, matrix games in which a saddle point cannot be found lead to more complex linear programming tasks.{{newline}}If we have enough information, for example, a competitive contest between two or more players in the market can be described using a specific matrix game. These will be the aim of this contribution. In a few selected practical examples, we will show how linear programming can be used in a managerial position. For each situation, we first demonstrate a mathematically formal description of the problem, then find the optimal solution and finally interpret the result from an economics perspective.{{newline}}First described conflict is between two banking institutions regarding the level of interest rates. The second example will show whether a strike is an appropriate strategy for raising wages. The third conflict situation concerns workers under a new manager who wants to introduce weekend work. And the last presented managerial decision is the choice of a suitable future investment.;Jana%Heckenbergerova%University of Pardubice%Czechia%jana.heckenbergerova@upce.cz
44;Mária Trnovská;Path-based DEA models: a unified approach through envelopment and multiplier form;https://easychair.org/conferences/submission_view?a=32726078&submission=6860129;trnovska@fmph.uniba.sk;Data envelopment analysis,Returns to scale analysis,Directional distance function model,Hyperbolic distance function model;Data envelopment analysis models are commonly presented in two forms: the envelopment form and the multiplier form. Both forms are essential for proper interpretation and application of the model. In this contribution, we focus on a specific subclass of DEA models called path-based models. This subclass includes radial, directional distance function, and hyperbolic distance function models as special cases. We present a general envelopment framework for path-based models that allows them to be extended to arbitrary data and discuss some of their properties. We also derive the general multiplier form and the optimality conditions, which can be used in the returns-to-scale measurement. Finally, we demonstrate the applicability of these results with numerical examples.;Mária%Trnovská%Comenius University in Bratislava%Slovakia%trnovska@fmph.uniba.skˇMargaréta%Halická%Comenius University in Bratislava%Slovakia%halicka@fmph.uniba.sk
45;Pavel Pražák;Discrete-time Dynamic Exchange Rate Overshooting Model;https://easychair.org/conferences/submission_view?a=32726078&submission=6860216;pavel.prazak@uhk.cz;exchange rate,difference equations,discrete dynamical systems,stationary solution,qualitative analysis,stability;The paper deals with a discrete-time version of the overshooting model. Insights into short-run currency market behaviour are often provided by the exchange rate overshooting principle, which illustrates how equilibrium levels are initially quickly overshooted before a slower adjustment occurs. The model is formulated as a system of difference equations using lagarithmic transformation. Within this framework, transient exchange rate deviations within discrete time intervals are also analysed. In addition, the model can be used to formulate and discuss a qualitative analysis of the various possible policy options.;Pavel%Pražák%University of Hradec Kralove%Czechia%pavel.prazak@uhk.cz
46;Jan Volný;Influence of Weights in Central Weight Vector on Additional Information in SMAA Method.;https://easychair.org/conferences/submission_view?a=32726078&submission=6860284;vol0133@vsb.cz;Stochastic Multi-criteria Acceptability Analysis (SMAA),Decision-Making Process,Central Weight Vector,Additional Information,Decision Optimization;Decision-making processes often rely on stochastic models due to the inherent uncertainty in evaluating alternatives. This study investigates how the weights of criteria within the central weight vector, derived via the Stochastic Multi-criteria Acceptability Analysis (SMAA) method, affect the valuation of additional information. Applying SMAA across various decision-making scenarios, we examined the correlation between criteria weights and the variability of acceptability and confidence indices after integrating supplementary data. Our analysis reveals a direct relationship: higher weights in the central weight vector significantly increase the impact of additional information on alternative evaluations, as evidenced by increased variance in both indices. These findings offer a strategic framework for decision-makers to efficiently allocate resources towards obtaining additional information for the most influential criteria and alternatives, thereby optimizing the decision-making process.;Jan%Volný%VŠT - TUO%Czechia%vol0133@vsb.cz
47;Ondřej Šimpach;Improvement of Methods of Fertility Rates Modelling;https://easychair.org/conferences/submission_view?a=32726078&submission=6860290;ondrej.simpach@vse.cz;fertility rates,Lee Carter model,policy planning,stochastic modelling;Fluctuations and trends of fertility rates development do not have to be regular or long-term. Knowledge of fertility rates is needed for policy planning and public ad-ministration.Therefore, we focus on the modelling of the fertility rates in the Czech Republic. Particularly, we apply standard Lee-Carter model with time-independent parame-ters ax and bx and time-varying index kt. Hyndman “demography” package in RStudio software is utilized. Because parameter ax (the average value of the empiri-cal time series) can be biased, we suggest an approach for its improvement.We utilize functional data (fertility rate, age, year), where fertility rate is a function of women's age for time period 1950 to 2022. There are 4 models with different ax parameter compared: a) standard parameter of the Lee-Carter model, b) median of age-specific fertility rates, c) ax calculated on data 1999–2022, and d) ax calculated on data 2008–2022. However, no approach was found to be better than the original calculated as simple arithmetic means of fertility rates in specific age which had the lowest mean squared error.These results are important for subsequent analyses because for working with de-mographic data about fertility it is important to consider the most recent data, which are not significantly skewed and influenced by a range of factors.;Ondřej%Šimpach%University of Economics Prague%Czechia%ondrej.simpach@vse.cz
48;Vojtěch Vávra;Comparison of Python Metaheuristic Packages;https://easychair.org/conferences/submission_view?a=32726078&submission=6860304;vojtech.vavra@vse.cz;Python,metaheuristics,DEAP,MEALPY,NiaPy,Opytimizer,PyGmo;"Metaheuristic approaches are utilized to find sub-optimal solutions within a reasonable timeframe. This is crucial for NP-hard problems such as the traveling salesman problem, the vehicle routing problem and the knapsack problem. However, identifying the appropriate software to execute such algorithms is not straightforward. This paper presents a comprehensive study aimed at identifying a suitable package in the programming language Python. Python is one of the most widely used programming languages worldwide and is employed daily by numerous companies. The sheer number of packages available can be overwhelming, making it challenging to select the right tool for a given problem.The objective of this paper is to locate and compare such packages, preselect suitable ones and determine the best package or packages. The criteria for decisionmaking include: first, the number of algorithms implemented; second, flexibility, customization and tuning capabilities; third, performance; fourth, quality of documentation; fifth, the learning curve in relation to the knowledge of AI; sixth, maintenance; seventh, community support and finally, the overall health of the package.";Vojtěch%Vávra%Prague University of Economics and Business - Faculty of Informatics and Statistics%Czechia%vojtech.vavra@vse.cz
49;Petr Fiala;Model of network interconnections;https://easychair.org/conferences/submission_view?a=32726078&submission=6860320;pfiala@vse.cz;Network industry,Competition,Cooperation,Biform games;In today's economy, many activities are networked. The importance of network industries that deliver products and services is growing. Traditionally, only the effects of competition have been analysed within networks. Companies are increasingly finding that even the cooperation of competitors can bring benefits to all involved. Network interconnections are analysed, where networks not only provide services on their own network, but also allow access to foreign networks. The paper a model and analyses of co-opetition in network industries using biform games as a combination of the non-cooperative and cooperative games theory. The authors propose the division of the biform games into sequential and simultaneous games. Theproposed model can be solved as a sequential biform game.;Petr%Fiala%Prague University of Economics and Business%Czechia%pfiala@vse.czˇRenata%Majovska%University of Finance and Administration, Prague%Czechia%renata.majovska@mail.vsfs.cz
50;Dominika Bordácsová;Identification, Generation, and Evaluation of Intralogistic Solutions;https://easychair.org/conferences/submission_view?a=32726078&submission=6860643;bor0151@vsb.cz;Intralogistics,Optimization,Scenario Analysis;This contribution focuses on the identification and generation of intralogistic solution combinations that meet specific customer requirements. The classical framework and processes are innovated based on expert experiences and the future development of the company in a competitive environment. The proposed system utilizes historical data and expert knowledge while respecting customer requirements when establishing individual scenarios. For each scenario, an intralogistic solution that minimizes the final cost while adhering to all constraints is found through optimization. For the most probable scenario, a distribution including risk will be sought, and changes in the solution's performance will be monitored. Performance values will be compared with remaining scenarios for modeling the time intensity of picking within the designed intralogistic solutions. The obtained results enable the identification of the impacts of time intensity on performance within the examined scenarios. In this way, we allow for a more realistic and precise simulation of intralogistic processes. A critical part of our method is the evaluation of various scenarios, which enables us to quantify the impacts of uncertainty in picking speed on the performance of automated systems and to identify the optimal solution for each unique customer situation. This work offers a new perspective on planning and managing intralogistics by combining stochastic modeling with practical market needs. Our analysis results demonstrate how efficient and adaptive intralogistic systems can be when properly designed and calibrated with consideration for the inherent uncertainties of operations. Our findings provide a valuable foundation for further research and development in the field of automated intralogistics and offer practical guidelines for implementation in real logistic operations.;Dominika%Bordácsová%Vysoká škola báňská - Technická univerzita Ostrava%Czechia%bor0151@vsb.czˇJana%Hančlová%Vysoká škola báňská - Technická univerzita Ostrava%Czechia%jana.hanclova@vsb.czˇLucie%Chytilová%Vysoká škola báňská - Technická univerzita Ostrava%Czechia%lucie.chytilova@vsb.cz
51;Imma Lory Aprea;A diffused and thickening soil monitoring model for evaluating the impact of climate change on agriculture;https://easychair.org/conferences/submission_view?a=32726078&submission=6860982;immalory.aprea@uniparthenope.it;Risk-cost analysis,Sensor networks,Structural health monitoring,Sustainability criteria,Climate change;The sensor allocation problem and processing data detected by sensor devices represent a challenging topic in the agriculture field. More specifically, acquisition data in soil monitoring aims to provide information about the effects of climate change on soil health in terms of soil fertility, salinity, moisture levels, and nutrient levels. These soil structural parameters, which directly affect crop growth, give information about the monitoring system's reliability and allow the evaluation of the effectiveness of land management activities over time. This work proposes a diffused and thickening monitoring model to capture, according to an optimal approach, the most accurate information from sensor data, subject to a budget constraint and an environmental constraint. In detail, starting from a pre-existing network of zones, each controlled through a set of fixed diagnostic sensors, the aim is to identify further zones to be monitored by the same set of sensors to evaluate the soil health state. A geostatistical interpolation technique is used to estimate the soil structural parameters at any unsampled point of the area under analysis. These estimates are then used to measure the riskiness of extreme events, such as drought and floods, and then select the new zones to be added to the monitoring network. For the selection process, we consider a decision criterion based on the risk level of the occurrence of extreme phenomena under investigation and the comparison between the monitoring and non-monitoring costs for each zone of the examined area. Two types of constraints are involved: a budget constraint and an environmental constraint in order to limit the negative externalities that monitoring standard operations can have on the environment and provide the most sustainable monitoring network. This study describes the problem's resolution algorithm, and the zone selection criterion is tested using soil water temperature data in a dryland agricultural field.;Imma Lory%Aprea%University of Naples Parthenope%Italy%immalory.aprea@uniparthenope.it
52;Michaela Matoušková;Financial time series forecasting based on Artificial Intelligence Merlion;https://easychair.org/conferences/submission_view?a=32726078&submission=6861060;michaela.matouskova@tul.cz;Artificial Intelligence,Merlion,ARIMA,Commercial real estate,Python;In the past few years, Artificial Intelligence has advanced significantly technologically and is now easier to incorporate into analytics programs already in use.{{newline}}The aim of this study is to evaluate the performance of AI Merlion's modelling and forecasting techniques compared to established time series modelling software. Automatic and  semi-automatic model was built by AI Merlion, using Python library. The predictive capabilities of these models were compared with the ARIMA modelling using Eviews 13 software. By contrasting the models' forecasts with actual price movements, historical data on commercial real estate prices were utilized to assess each model's predictive accuracy.{{newline}}The acccurancy of a forecasting models was evaluate with commonly used Error measures based on squared, absolute and percentage errors: RMSE, MAE and sMAPE. By highlighting the possible benefits and drawbacks of AI-powered techniques in the context of financial time series modeling, this comparative analysis adds new insights to the field of prediction algorithms.;Michaela%Matoušková%Czech%Czechia%michaela.matouskova@tul.czˇPetr%Průcha%Czech%Czechia%petr.prucha@tul.cz
53;Jaroslav Janacek;On-line learning process for setting of heuristic parameters;https://easychair.org/conferences/submission_view?a=32726078&submission=6861189;jaroslav.janacek@fri.uniza.sk;Location problems,Pareto front approximation,heuristics,online learning process;Tuning of sophisticated optimization heuristics represents a substantial part of the heuristic application and it decides on final success or fail of the application. Tuning of a heuristic is usually based on proper setting of heuristic parameters at such values, which ensure the most efficient run of the heuristic. The admissible values of the parameters are known in advance only in rear cases. Mostly, they must be determined for each individual case separately. It can be performed by previous research during the phase of heuristic tuning or by a self-learning process, which is a part of regular heuristic performance. Within this paper, an on-line learning process applied to swap heuristic parameter setting is studied. The swap heuristic is run in the frame of the gradual refinement process assigned to the problem of Pareto front approximation. The heuristic environment assures frequent repeating of the heuristic run and thus, the learning process may lead to significant results. The issue of the learning process may be either a recommendable parameter value or it can be found that the parameter belongs to the class of sensitive parameters and no recommendable value exists.;Jaroslav%Janacek%Zilinska univerzita v Ziline%Slovakia%jaroslav.janacek@fri.uniza.skˇMarek%Kvet%University of Žilina - Faculty of Management Science and Informatics%Slovakia%marek.kvet@fri.uniza.sk
54;Marek Kvet;Swap heuristic parameter sensitivity;https://easychair.org/conferences/submission_view?a=32726078&submission=6861193;marek.kvet@fri.uniza.sk;Bi-criteria decision-making problems,parameter settings,swap heuristic;Swap operation used in neighborhood search heuristics can be modified in many ways introducing various parameters, which play an important role in the search termination rule, move accessibility definition and heuristic strategy determination. These parameters may considerably influence efficiency of the optimization process taking into account the objective function improvement and associated computational time. In this paper, we deal with the general problem of finding a good approximation of Pareto front, which consists of non-dominated p-location problem solutions. The applied gradual refinement process consists of enormous number of runs of the neighborhood search heuristic influenced by the parameter settings. In connection with the search for the correct setting of parameter values, we conducted research on swap heuristic behavior with the aim of revealing which parameters belong to the class of sensitive parameters.;Marek%Kvet%University of Žilina - Faculty of Management Science and Informatics%Slovakia%marek.kvet@fri.uniza.skˇJaroslav%Janacek%Zilinska univerzita v Ziline%Slovakia%jaroslav.janacek@fri.uniza.sk
55;Jakub Neugebauer;Dynamic Portfolio Optimization Under Robust Second Order Stochastich Dominance Model;https://easychair.org/conferences/submission_view?a=32726078&submission=6861261;jakub.neugebauer@vse.cz;Portfolio Optimization,Stochastic Dominance,Investment Strategies,S&P 500 Stocks;In this paper, different dynamic portfolio optimization strategies are examined under the usage of the robust second order stochastic dominance (RSSD) model, with a particular focus on its application to the stocks that are included in the S&P 500 index. In contrary to traditional investment approaches, which often rely on assumptions about historical returns and volatility, the RSSD model is recognized for its advanced handling of uncertainties and the dynamic characteristics of financial markets, proposing a good base for constructing portfolios. By subjecting various dynamic investing strategies to simulation and comparing their performances to the S&P 500 index benchmark, the potential of the RSSD model in augmenting portfolio returns and enhancing risk management is evaluated. Comprehensive analysis is employed with the aim of demonstrating how the RSSD model can be utilized by investors to make more informed and effective investment decisions, thereby optimizing the performance of their investment portfolios in the midst of market fluctuations. The outcomes of this research are intended to contribute significant insights for both academic investigation and practical implementation in the field of finance.;Jakub%Neugebauer%Czech%Czechia%jakub.neugebauer@vse.cz
56;Alena Pozdílková;Spatial Lag Model of the Real Estate Market in the Ústí nad Labem Region;https://easychair.org/conferences/submission_view?a=32726078&submission=6861271;alena.pozdilkova@uhk.cz;Spatial Lag Model,Spatial Modelling,Real Estate Market,Weights Matrix,Estimation of Unknown Parameters;The aim of the article is spatial modeling of the relationship of apartment prices between neighboring municipalities in the Ústí nad Labem Region and a numerical study with an empirical demonstration of the model's applicability based on residual analysis. The spatial lag model will be used for the calculation and the unknown parameters will be estimated by the least squares method. This model is often used to describe geoinformation phenomena. Formulating an appropriate spatial regression model is not a simple task. The simultaneous determination of an unknown system of dependencies and estimating the spatial lag coefficient is challenging. The source data were obtained by automatically downloading data from real estate advertising websites. Every day from January 2019 to March 2024, data was collected on the floor area of the advertised apartments and the requested purchase price. Average prices per one square meter of an apartment were calculated from them. Our calculation used a matrix of spatial weights based on the nearest neighbor method. A graphical representation of the results explains the context in the spatial configuration.;Alena%Pozdílková%University of Pardubice%Czechia%alena.pozdilkova@uhk.czˇJaroslav%Marek%University of Pardubice%Czechia%jaroslav.marek@upce.cz
57;Martin Boďa;Sensitivity of genders to economic fluctuations;https://easychair.org/conferences/submission_view?a=32726078&submission=6861292;martin.boda@umb.sk;Okun law,gender differences,sensitivity to economic fluctuations;For OECD countries, the paper studies whether it is male or female labour force that is more sensitive to fluctuations in overall economic activity. Towards this end, a two-stage procedure is applied. First, Okun's law is estimated in its unemployment-based and employment-based version in a time-varying framework for both males and females. Second, the estimated Okun coefficients are matched against sectoral and labour market characteristics of OECD economies, their demographic make-up and other explanatory factors. The Okun coefficients net of structural factors confirm that males are indeed more sensitive to business cycles. In comparison to the extant research, a more refined econometric procedure is employed and more robust findings are established.;Martin%Boďa%Matej Bel University in Banská Bystrica%Slovakia%martin.boda@umb.skˇMariana%Považanová%Matej Bel University in Banská Bystrica%Slovakia%mariana.povazanova@umb.skˇMichal%Struk%Jan Evangelista Purkyně in Ústí nad Labem%Czechia%michal.struk@ujep.czˇMichaela%Tichá%Jan Evangelista Purkyně in Ústí nad Labem	%Czechia%michaela.ticha@ujep.cz
58;Ondřej Sokol;Fractional Orienteering Problem with Mandatory Nodes: Ant Colony Heuristic;https://easychair.org/conferences/submission_view?a=32726078&submission=6861335;ondrej.sokol@vse.cz;orienteering problem,ant colony optimization,heuristic;Routing problems pose significant challenges in optimization. The fractional orienteering problem is no exception. While the Charnes–Cooper transformation allows for linearization of the model, efficiently solving large instances necessitates the use of heuristics. In this study, we propose an innovative algorithm based on ant colony optimization to address the fractional orienteering problem. Our approach involves a non-trivial adaptation of the basic ant colony optimization framework to account for mandatory nodes, enhancing its performance in real-world scenarios.;Ondřej%Sokol%Prague University of Economics and Business%Czechia%ondrej.sokol@vse.czˇVladimír%Holý%Prague University of Economics and Business%Czechia%vladimir.holy@vse.czˇJan%Pelikan%Prague University of Economics and Business%Czechia%jan.pelikan@vse.cz
59;Markéta Matulová;Construction of a new DEA-based Compo-site Index for Circular Economy Assessment in the EU;https://easychair.org/conferences/submission_view?a=32726078&submission=6861369;8987@mail.muni.cz;Circularity,Composite Index,Data Envelopment Analysis;In recent years, there has been growing interest in exploring the concept of the circular economy as a potential solution for enhancing the sustainability of our economic system. The development of circular economy indicators provides valuable insights allowing the evaluation of the progress on the path to circularity and sustainability. On the other hand, composite indicators often stir controversies about the unavoidable subjectivity that is connected with their construction. Usually, the normalized sub-indicators are just added, sometimes with certain weights associated with the sub-indicators. We will depart from that approach and compute alternate composite index for 28 EU countries using flexible weights obtained by Data Envelopment Analysis. Using flexible weighting can promote buy-in from relevant stakeholders, making the final results more widely accepted. Additionally, DEA-based indicator provides more information on the relative performance of evaluated units and offers implications such as identifying target values of sub-indicators or selecting peer units for benchmarking purposes.;Markéta%Matulová%ESF, Masaryk University, Brno%Czechia%8987@mail.muni.cz
60;František Zapletal;On reflection the dependencies between criteria in their weights;https://easychair.org/conferences/submission_view?a=32726078&submission=6861393;frantisek.zapletal@vsb.cz;Fuzzy functional dependencies,weights,dependence,multi-criteria decision-making;"In multi-criteria decision-making (MCDM), the weights, expressing the importance of criteria for a decision-maker, are a crucial factor. Usually, the MCDM methods assume mutually independent criteria. On the other hand, in some situations, this assumption is too strong and could bring heavily distorted results. The literature provides some ways how to reflect such dependencies in the weights of criteria (e.g., CRITIC method or Choquet integral) but they suffer from weaknesses like the direction of dependency. This paper adopts the concept of fuzzy functional dependencies (FFDs) and criteria weights assignment. FFDs reveal not only the strength of the dependence but also its direction (causality); they can work with the uncertain input data (including qualitative variables or fuzzy numbers). The goal of this paper is to propose a model which uses FFDs to adjust the criteria weights in order to reflect the impact of dependencies. The model is verified using a real-life example.";František%Zapletal%VSB-TU Ostrava%Czechia%frantisek.zapletal@vsb.czˇMiroslav%Hudec%VSB-TU Ostrava%Czechia%miroslav.hudec@vsb.czˇMarek%Štěpán%VSB-TU Ostrava%Czechia%marek.stepan.st@vsb.czˇMiljan%Vućetić%VSB-TU Ostrava%Czechia%miljan.vucetic@vsb.cz
61;Marek Štěpán;Creating a multi-criteria employee evaluation model using fuzzy functional dependencies;https://easychair.org/conferences/submission_view?a=32726078&submission=6861425;ste0405@vsb.cz;criteria weights,fuzzy functional dependencies,multi-criteria decision-making methods;Several different methods can be utilized to examine the interdependence of individual criteria in a multi-criteria model for employee evaluation or selection, and the influence of these relationships on the weights of criteria. These methods include, for example, correlation analysis, fuzzy functional dependencies (FFD), or principal component analysis. This work focuses on creating a model utilizing fuzzy functional dependencies, aiming to analyze the relationships between criteria for employee evaluation, which are not represented by classical sets of values but by fuzzy sets. The results obtained through FFD are further used to calculate the weights of individual criteria within the selected multi-criteria method.;Marek%Štěpán%VŠB - TUO%Czechia%ste0405@vsb.cz
62;Lucie Chytilová;Measuring and Analyzing the Technical Efficiency of Floorbal Players;https://easychair.org/conferences/submission_view?a=32726078&submission=6861447;chytilova@pef.czu.cz;Data Envelopment Analysis,floorball,efficiency;Floorball, a global phenomenon, demands peak player efficiency for teams to thrive. However, current evaluation methods are often subjective. This research introduces objective tools for floorball clubs, managers, and coaches. We are using Data Envelopment Analysis (DEA), specifically the basic CCR and BCC models with different variables according to the type of players. We assess the technical efficiency of players in the Czech Extraliga, the top men's league, across an entire season. Analysing players overall, then by attackers and defenders, we identify areas for improvement based on playing position and team affiliation. This novel approach demonstrates the potential of DEA for efficiency measurement, paving the way for a more systematic and objective methodology and coaching in floorball player assessment.;Lucie%Chytilová%Czech University of Life Sciences Prague%Czechia%chytilova@pef.czu.czˇMichal%Pažák%VŠB - Technical university of Ostrava%Czechia%michal.pazak.st@vsb.cz
63;Ladislav Beranek;The use of hypergraphs for recommender system design;https://easychair.org/conferences/submission_view?a=32726078&submission=6861474;beranek@ef.jcu.cz;Network systems,E-commerce,Recommendation,Hypergraphs;Currently, recommendation systems are an integral part of e-commerce business platforms. E-commerce systems can obtain large amounts of customer data, such as which products users purchase or data that customers use to search for products. This data is used for personalized recommendations, to predict search trends, or to improve search results. In general, recommender systems deal with two problems. The first problem is a low number of purchases or searches related to specific prod-ucts, and the second is that queries may be directed more likely to only some popu-lar items. This second problem is referred to as disassortative mixing. To overcome these problems, we will use a hypergraph and a bipartite graph in our proposal of a prediction algorithm for a recommender system. It will allow us to utilize additional information from customer relationships. Our procedure treats all products appear-ing in the same customer session as a single hyperedge. We assume that a common purchasing interest unites items in customer sessions. It allows the initial bipartite graph to be transformed into a hypergraph. We conducted experiments with two e-commerce datasets. Experimental results show that the proposed solution provides good results compared to other algorithms.;Ladislav%Beranek%University of South Bohemia, Faculty of Economics%Czechia%beranek@ef.jcu.czˇRadim%Remes%University of South Bohemia, Faculty of Economics%Czechia%inrem@jcu.czˇJiri%Homan%University of South Bohemia, Faculty of Economics%Czechia%homanj00@ef.jcu.czˇJan%Fesl%University of South Bohemia, Faculty of Economics%Czechia%jfesl@jcu.czˇMichal%Konopa%University of South Bohemia, Faculty of Economics%Czechia%konopm05@jcu.cz
64;Eva Vychodilová;Analysis of the impact of the reduction of state support for research and development;https://easychair.org/conferences/submission_view?a=32726078&submission=6861477;eva.vychodilova@tul.cz;State support,Research and development,Funding,Time series,Model the structural breaks;Although state support for research and development (R&D) has been growing steadily in recent years, the rate of growth is slowing considerably. Forecasts predict a further year-on-year decline in state R&D spending, raising concerns about its impact on research projects and innovation activities within higher education, research institutions, and the private sector. This raises a fundamental question: how will universities and firms adapt to this changing environment of public support for R&D?{{newline}}Extensive research across countries highlights the importance of promoting collaboration and networking between universities (knowledge production sector) and the private sector (application sector). This collaboration between universities and industry is widely regarded as a key driver of innovation, leading to technological progress, product development, and economic growth.{{newline}}This study aimed to model the evolution of time series describing the likely response of universities and firms to changes in government support for R&D and to identify and model the structural breaks that occur in these series. Having captured the trend of the time series, a prediction of the time series was then made. Chow's forecasting test was chosen as the extrapolation criterion.{{newline}}Declining state support for R&D requires a deeper understanding of how universities and firms will adapt. Using time series analysis and structural break detection, this study aims to shed light on this crucial question and inform future R&D policy and university-industry collaboration strategies.;Eva%Vychodilová%Technical University of Liberec%Czechia%eva.vychodilova@tul.czˇMichaela%Matoušková%Technical University of Liberec%Czechia%michaela.matouskova@tul.cz
65;Lucie Chytilová;A Two-Stage DEA Model for Evaluating the Efficiency of SMEs with Multi-Year Accounting Data;https://easychair.org/conferences/submission_view?a=32726078&submission=6861479;chytilova@pef.czu.cz;Data Envelopment Analysis,two-stage,small and medium business,efficicency;This study proposes the extension of the two-stage Data Envelope Analysis (DEA) model to assess the efficiency of small and medium enterprises (SMEs). The model leverages multi-year accounting data and incorporates a temporal dimension to capture the dynamic nature of SME operations. The primary focus is on evaluating these enterprises' stability and efficiency. The proposed model decomposes the evaluation process into two sub-stages: Stage 1 focuses on human capital efficiency, and Stage 2 assesses business efficiency. Outputs from Stage 1 serve as inputs for Stage 2, reflecting the sequential nature of these processes. These phases influence each other, even in different periods. Data from 2020 to 2022 are used. This approach allows for a more comprehensive evaluation by capturing the effectiveness of human capital utilisation (Stage 1) and its subsequent translation into business efficiency (Stage 2). The analysis will categorise SMEs into efficient and inefficient groups, further delving into efficiency levels at each stage. By examining the relationships between human capital, business skills, and overall efficicency, the study aims to identify key drivers of efficiency in SMEs. Finally, based on the findings, the research proposes practical recommendations for enhancing SME operations and developing effective business support mechanisms.;Lucie%Chytilová%Czech University of Life Sciences Prague%Czechia%chytilova@pef.czu.czˇHana%Štverková%VŠB - Technical university of Ostrava%Czechia%hana.stverkova@vsb.cz
66;Michaela Sedláková;The Impact of Initial Price History on Asset Price Volatility: Insights from a Learning to Forecast Experiment;https://easychair.org/conferences/submission_view?a=32726078&submission=6861483;michaela.sedlakova@vsb.cz;behavioral finance,experimental economics,expectations;The effect of the initial price history on asset price volatility is studied using a Learning to Forecast experiment (hereinafter LtF). Participants are tasked with predicting the future prices of three distinct risky assets over many consecutive periods. In contrast to previous LtF experiments that focused on a single risky asset, this research allows participants to compare the price trajectories of individual assets. One asset is characterized by a very stable initial price development compared to the other two assets. Given that all risky assets share the same fundamental value, we can investigate the effect of different initial price history on the overall price dynamics. Our conjecture is that the asset with a stable initial price history will exhibit lower volatility compared to the other two assets. This hypothesis is verified through statistical tests that are applied with respect to selected measures of volatility – relative absolute deviation from the fundamental price and variance. From the results, it is clear that the asset characterized by a stable initial price history in most cases demonstrates reduced price volatility. Moreover, we find that the initial price history significantly impacts participants’ coordination behaviour during the experiment.;Michaela%Sedláková%VSB – Technical University of Ostrava, Faculty of Economics%Czechia%michaela.sedlakova@vsb.cz
67;Jiří Hozman;Application of chooser options to valuation of investment opportunities;https://easychair.org/conferences/submission_view?a=32726078&submission=6861484;jiri.hozman@tul.cz;real options pricing,flexibility value,chooser option,Black-Scholes model,discontinuous Galerkin method;Real options approach can be applied to a variety of investment opportunities to help investors improve risk management and make more informed decisions. Since a chooser option is a contract written on the maximum of the set of individual real options providing certain (mutually different) investment opportunities, this flexibility makes chooser options particularly relevant for valuing investment opportunities that involve uncertainty and the need for strategic decision-making. In this paper, we present an incorporation of chooser options into the valuation process and examine their valuation via contingent claims framework under single-factor uncertainty. The resulting PDE problems are of the Black-Scholes type and are solved using a discontinuous Galerkin approach. Finally, we provide a simple conceptual example of how chooser options can be used in investment scenarios facing a choice between expansion, contraction, or total abandonment.;Jiří%Hozman%Technical University of Liberec%Czechia%jiri.hozman@tul.czˇTomáš%Tichý%VSB-TU Ostrava%Czechia%tomas.tichy@vsb.cz
68;Lucie Chytilová;The Energy Mix in Europe: A Panel Regression Analysis;https://easychair.org/conferences/submission_view?a=32726078&submission=6861487;lucie.chytilova@vsb.cz;Energy mix,Europe,Panel regression,Renewable Energy,Non-renewable energy sources;The energy mix in Europe is undergoing a significant transformation with an emphasis on decarbonisation and increasing energy security. This work examines trends in the EU's energy mix using panel regression. The analysis includes data from 28 EU countries from 2000-2022. It focuses on the development of energy consumption, energy production from renewable and non-renewable sources and dependence on energy imports.{{newline}}The results show that energy consumption in the EU is growing slightly while energy production from renewable sources is rising significantly. Dependence on energy imports is decreasing but still high. Panel regression reveals that several factors influence the evolution of the energy mix in the EU, including economic growth, energy prices, climate policy, and energy security.{{newline}}The thesis further examines specific trends in individual EU countries and identifies key challenges and opportunities for transforming the energy mix. In conclusion, it summarises the main results and proposes policy recommendations for achieving a sustainable and secure energy mix in Europe.;Lucie%Chytilová%Vysoká škola báňská – Technická univerzita Ostrava%Czechia%lucie.chytilova@vsb.czˇJana%Hančlová%Vysoká škola báňská – Technická univerzita Ostrava%Czechia%jana.hanclova@vsb.cz
69;Jana Hanclova;Evaluation of the efficiency of national energy markets in 27 EU countries in 2011-2022;https://easychair.org/conferences/submission_view?a=32726078&submission=6862111;jana.hanclova@vsb.cz;data envelopment analysis,energy market,European Union,renewable energy,greenhouse gas emissions;The European energy market is characterized by a diverse mix of energy sources, including fossil fuels, nuclear power, and an increasing share of renewable energy sources such as wind, solar, and biomass. The market operates within the framework of the European Union (EU), with regulations aimed at promoting competition, ensuring security of supply, and reducing greenhouse gas emissions.{{newline}}The contribution is devoted to the evaluation of the efficiency of national energy markets in 27 EU countries in the years 2011-2022. Attention is paid to the share of renewable sources and undesirable production of emissions. The evaluation is based on a modified model of data envelopment analysis with undesirable outputs. We use direct distance function, non-proportional changes, and increasing returns to scale. The results document that the critical output is precisely the share of renewable resources and that there is no significant improvement in the examined period. The second critical output is the production of emissions, where the situation usually improves over the years. The analysis contributes to revealing the causes of the development of unfavorable trends in the energy markets of EU countries.;Jana%Hanclova%VSB-Technical University of Ostrava%Czechia%jana.hanclova@vsb.czˇLucie%Chytilova%VSB-Technica University of Ostrava%Czechia%lucie.chytilova@vsb.czˇDominika%Bordacsova%VSB-Technical University of Ostrava%Czechia%dominika.bordacsova.st@vsb.cz
70;Dana Černá;Wavelet Method for Pricing One-Stage Expansion Options under Stochastic Volatility;https://easychair.org/conferences/submission_view?a=32726078&submission=6863826;dana.cerna@tul.cz;option to expand,real option,stochastic volatility,wavelet method;One-stage expansion options are a category of real options that enable expanding an investment project by a predetermined factor at a certain cost on a specified future date. Assuming that the price of the underlying commodity and its volatility follow a geometric Brownian motion, the valuation model for expansion options is represented by several partial differential equations. The objective is to introduce a pricing model for one-stage expansion options, propose an efficient wavelet-based method for its numerical solution, and implement this method to address practical problems. The method employs the Crank-Nicolson scheme combined with the Galerkin method using a cubic spline wavelet basis. Its application to a benchmark problem within the iron-ore mining industry demonstrates the suitability and applicability of the method and also highlights its numerical advantages, which include higher-order convergence and a small number of iterations necessary to attain the desired accuracy.;Dana%Černá%Technical University of Liberec%Czechia%dana.cerna@tul.cz
71;Josef Jablonský;Re-calculation of scientometric indicators of ORMS journals by non-traditional models. ;https://easychair.org/conferences/submission_view?a=32726078&submission=6868295;jablon@vse.cz;data envelopment analysis,journal impact factor,article influence score,ranking;Performance and citation impact of scientific journals are measured by traditional metrics such as impact factor, article influence score, journal citation indicator, and others. While the impact factor is based on the total number of citations and does not reflect the quality of journals cited, the article influence score considers the past importance of the citing journals. This paper aims the analysis and re-calculation of the performance of journals by data envelopment analysis (DEA) models. Traditional radial and SBM DEA models with weight restrictions where the outputs of the models are the citation counts from Q1 to Q4 categories and other journals according to the impact factor are applied. The results of the study are illustrated on the set of 80 journals from the Web of Science category Operational Research and Management Science (ORMS). The dataset for the study was obtained from the Journal Citation Reports in the period from 2017 until 2022. The relative efficiency scores and the ranking of the journals obtained by the models are presented and compared with traditional metrics.;Josef%Jablonský%Prague University of Economics and Business%Czechia%jablon@vse.cz
72;Jenn-Rong Lin;THE LONG-TERM-CARE CAREGIVER ROUTING AND SCHEDULING PROBLEM WITH CONSIDERATIONS OF STOCHASTIC TRAVEL TIMES AND SERVICE TIMES;https://easychair.org/conferences/submission_view?a=32726078&submission=6872344;jrlin@email.ntou.edu.tw;Long term care,Caregiver,routing and scheduling,Stochastic vehicle routing;With increasing elderly citizens yearly, there are more and more elderly people need long-term care (LTC) service. The long-term care service institutions are responsible for providing home-based LTC service according to the plan setting up by the responsible integrated community service center and family members of the elderly in need. This is a huge challenge to long-term care service institutions since there is a growing demand of home-based LTC service but with insufficient home-based LTC caregivers for providing service.  Efficient and effective caregiver routes and schedules are essential to conquer the challenge. The robust planning of home-based LTC caregiver routes and schedules is a very intricate engineering task, since it requires considerations of the management of caregivers’ working rules and workloads, the matching of caregivers’ skills and customers’ service requests and their preferences and complicated analysis among the selection of customers, the staffing of full-time and part-time caregivers, and numerous time-window and space constraints which are highly correlated with each other in a plan horizon. Therefore, we aim to develop a robust planning model to help LTC service institutions plan home-based caregiver routes and schedules. We first formulate and analyze a deterministic planning model for home-based LTC caregiver routing and scheduling with the considerations of working rules, workloads, service items, service time windows and service route duration. We then formulate and analyze a robust planning model for home-based LTC caregiver routing and scheduling in urban areas with the additional considerations of stochastic travel times and stochastic service times and penalty costs for violating working rules. A scenario-based stochastic model is proposed for this problem. A meta-heuristics embedded with a routing heuristic is developed to solve the model. Numerical examples are created to illustrate and to test the proposed models.;Jenn-Rong%Lin%National Taiwan Ocean University%Taiwan%jrlin@email.ntou.edu.tw
73;Petr Krautwurm;Comparing Measures of Product Relatedness on Data from Czech Drugstore Retail Chain;https://easychair.org/conferences/submission_view?a=32726078&submission=6874160;petr.krautwurm@vse.cz;Elasticity of substitution,Cross-price elasticity,Individual data,Substitutes,Complements;This article examines Robinson's elasticity of substitution estimator alongside cross-price elasticity, from both theoretical and empirical perspectives, focusing on their application in classifying products as substitutes or complements. Initially, we illustrate the theoretical interconnections between these measures, demonstrating that they should consistently classify products similarly. Furthermore, we introduce a novel approach to adjust for the presence of perfect substitutes in individual transactional datasets, a common challenge in economic analyses. By aggregating perfect substitutes, we maintain the integrity of product relations, thus enhancing the utility of the data without introducing biases. Utilizing this adjusted dataset, we apply both measures to assess product relatedness and find that they effectively and consistently classify products as either substitutes or complements, validating theoretical predictions and our methodological innovations.;Petr%Krautwurm%Prague University of Economics and Business%Czechia%petr.krautwurm@vse.cz
74;Hossein Moosaei;Maximizing Classification Efficiency: Integration of Optimization with Twin Support Vector Machine;https://easychair.org/conferences/submission_view?a=32726078&submission=6874171;hmoosaei@gmail.com;Optimization,SVM,Twin SVM;This paper presents an exploration of the Twin Support Vector Machine (TSVM), an advanced variant of the traditional Support Vector Machine (SVM) algorithm tailored for classification tasks with real-world datasets. The TSVM algorithm enhances robustness and efficiency, rendering it suitable for a wide array of machine learning scenarios. In this study, we investigate the theory behind TSVM and its practical applications, shedding light on its capabilities and advantages over standard SVMs.{{newline}}Moreover, we delve into the integration of TSVM with optimization techniques and machine learning algorithms, elucidating how this fusion can amplify performance and address complex challenges in diverse domains. By combining the strengths of TSVM with optimization methods, practitioners can refine models and fine-tune parameters to achieve optimal classification results. Additionally, leveraging TSVM within machine learning pipelines can enhance pattern recognition and predictive modeling tasks, leading to more accurate and reliable outcomes.;Hossein%Moosaei%Jan Evangelista Purkyně  University%Czechia%hmoosaei@gmail.com
75;Jan Rejthar;Choking Hazard: Surviving the Heat of Competitive Counter-Strike;https://easychair.org/conferences/submission_view?a=32726078&submission=6875316;rejj02@vse.cz;Counter-Strike,Choking under pressure,Esports,Economics of sports;This article delves into choking under pressure among Counter-Strike players, aiming to identify determinants of pressure in professional competitions. Employing regression analysis, the study examines whether players' performance is affected by the intense pressure often encountered in competitive gaming scenarios. Drawing from the complete competitive history of Counter-Strike: Global Offensive present at archive of hltv.org consisting of nearly 77,000 matches, the research reveals parallels with traditional sports psychology, showcasing that players indeed experience performance decline under pressure.{{newline}}A key finding of the study is the positive mediating effect of experience on players' susceptibility to choking under pressure. Experienced players exhibit greater resilience to pressure-induced performance decrements compared to their less seasoned counterparts.{{newline}}This research enhances our understanding of the psychological intricacies within esports, emphasizing the importance of experience in shaping player performance under pressure. By leveraging comprehensive data and rigorous regression analysis techniques, the study offers actionable insights for player development and performance optimization in competitive gaming contexts.;Jan%Rejthar%University of Economics and Business, Prague%Czechia%rejj02@vse.cz
76;Dominik Kavrik;A Comparative Analysis of S-VAR and Traditional Filtering Methods in Output Gap Estimation;https://easychair.org/conferences/submission_view?a=32726078&submission=6875338;kavd00@vse.cz;Taylor Curve,Monetary Policy,Output Gap Estimation;The Taylor curve, illustrating the trade-off between inflation variability and output gap fluctuations, is pivotal in shaping monetary policy decisions. Traditional analyses often utilize the Hodrick-Prescott filter to estimate the output gap, which may introduce distortions affecting policy interpretation. This paper proposes an alternative approach by employing the Structural Vector Autoregression (S-VAR) model to filter the output gap and compares its effectiveness against standard methods including the Hodrick-Prescott, Christiano-Fitzgerald, and Beveridge-Nelson techniques. This comparative analysis aims to uncover how different filtration methods influence the stability and accuracy of the Taylor curve estimates. The results suggest that the choice of filtering technique not only significantly alters the perceived efficacy of monetary policy but also necessitates a reassessment of methodological preferences in macroeconomic analysis. This study underscores the importance of selecting robust filtering tools in the empirical evaluation of key macroeconomic relationships.;Dominik%Kavrik%Prague University of Economics and Business%Czechia%kavd00@vse.cz
77;Helena Myšková;Global optimization problem in max-plus algebra;https://easychair.org/conferences/submission_view?a=32726078&submission=6876335;helena.myskova@tuke.sk;max-plus algebra,max-plus linear model,constraint function,global optimization,application in distributed system;The behavior of discrete-event systems, in which individual components move from event to event, rather than varying smoothly in time, is often described using max-plus algebra. Max-plus linear systems whose basic operations are maximization and addition can be used to describe a class of dynamical systems with synchronization but no concurrency or choice, although such systems are generally nonlinear in conventional algebra. Applications of max-plus linear systems arise in the context of manufacturing plants, traffic management, high-performance screening systems, etc. Global optimization is an optimal control problem that finds the global minimum or maximum of a function or set of functions over a given set. The growing interest in global optimization for max-plus linear systems is related to its importance in both theory and applications. Consider the global optimization problem of minimizing the max-plus product $A.x$, where $A$ is a given matrix and the constraint set is the set of column vectors $x$ such that the sum of $k_j.x_j$ is equal to $c$, where $c$ is a given positive real constant and $k_j$ are non-negative numbers with sum equal to 1. We will show that the solvability of a given global optimization problem is independent of the number $c$ if the components of the vector $x$ can be also negative. From a practical point of view, we further consider the solvability of the global optimization problem with non-negative constraints. We will propose an algorithm to find the set of all values of $c$ for which the problem is solvable. We will show the practical importance of the load distribution task, which focuses on a reasonable and transparent redistribution of the system load between processors in order to optimize the overall system performance.;Helena%Myšková%Technical University of Košice%Slovakia%helena.myskova@tuke.sk
78;Tomasz Brzęczek;Research on assortment selection problem integrated with the capacitated optimal order optimization;https://easychair.org/conferences/submission_view?a=32726078&submission=6876837;tomasz.brzeczek@put.poznan.pl;merchandise planning,optimal assortment,stochastic demand;Assortment planning belongs to operations research classical problems. This research provides literature review on models classification, solving programmes and techniques. Economy branches prevailing in application research are specified regarding results crossvalidation or methods replication with some new results being presented. Further research propositions are presented.;Tomasz%Brzęczek%Poznan University of Technology%Poland%tomasz.brzeczek@put.poznan.pl
79;Pavel Beránek;The Impact of Language-Based AI on Wealth Inequality: Insights from Multi-Agent Simulations;https://easychair.org/conferences/submission_view?a=32726078&submission=6876844;pavel.beranek@ujep.cz;Boltzmann Wealth Distribution,Economic Inequality,AI in Economic Modeling,Multi-agent systems,Large-language models;This research explores the integration of Large Language Models (LLMs) in multi-agent simulations to study the effects of natural language bargaining on wealth distribution. Utilizing advanced language models—GPT-4 with 1.7 trillion parameters and the smaller Phi-2 with 3 billion parameters—this study seeks to uncover new insights into economic behaviors within the Boltzmann distribution model, enriching traditional economic models with sophisticated, realistic agent interactions. Through a series of simulations set in a grid-based network topology, we investigate how LLM-mediated negotiations impact wealth distribution among agents under varying agent attributes and external economic conditions. Our research questions specifically address the influence of LLM-based bargaining on wealth distribution through generated negotiation dialogues, the emergence and effectiveness of negotiation strategies, variations in the Gini coefficient across different simulation setups, and the capacity of LLMs to reveal emergent properties not detectable in traditional models. We anticipate our findings will encourage interdisciplinary collaboration among AI, economics, and social and psychological sciences. This study not only demonstrates the significant capabilities of language-based AI in modeling complex economic interactions but also emphasizes the pivotal role of communication in influencing economic outcomes, thereby offering essential insights for crafting more equitable economic systems.;Pavel%Beránek%Jan Evangelista Purkyně University in Ústí nad Labem, Czech University of Life Sciences Prague%Czechia%pavel.beranek@ujep.cz
80;Robert Szczyrbak;Knapsack problem for build spare parts stock;https://easychair.org/conferences/submission_view?a=32726078&submission=6877892;rszczyrbak@agh.edu.pl;maintenance,Operational research,spare parts,knapsack problem;The manufacture of products and services involves the operation of machinery and equipment. In the course of operations, machinery gradually wears out, causing product defects, breakdowns or even to accidents. Product defects and failures strongly affect the OEE rate. Machine failures reduce the availability rate. The role of the maintenance department is to ensure the safe and continuous operation of the machinery fleet. For this purpose, the costs of technical materials and labor costs are incurred.{{newline}}Ensuring continuous operation of the machinery park is both the implementation of periodic inspections associated with the replacement of worn-out components, but also the minimization of repair time. The main factor causing an increase in repair time is the lack of possession of the required parts in the technical warehouse.{{newline}}In addition to standard indicators related to logistical aspects, it is worth using mathematical models for this purpose, such as integer programming models. To develop such a model, the research problem should be defined. It can be related both to reducing the value of the warehouse or total reduction of fixed costs, but also to raising the value of the machinery availability index. This paper shows knapsack problem, which can be used in technical warehouse. The main goal of this model is to minimize loses in production due failures.{{newline}}Securing in spare parts of the machinery park is a very important part of the management strategy. Decisions related to whether or not to have a particular component are worth justifying with appropriate arguments formed on the basis of analyses of availability and uniqueness of spare parts. It is also worth remembering that parts in stock are subject to obsolescence and in a few years a given component may not fully perform its functions.;Robert%Szczyrbak%AGH University of Krakow%Poland%rszczyrbak@agh.edu.pl
81;Katarzyna Gdowska;Enhancing Sustainability in Waste Collection - A Clustering Approach;https://easychair.org/conferences/submission_view?a=32726078&submission=6878129;kgdowska@agh.edu.pl;solid waste manageemnt,fleet management,clustering,mixed-integer programming;This study aims to enhance waste collection practices' sustainability in Tarnów, which currently relies on a diverse fleet of vehicles. Addressing the need for efficient strategic planning, the research focuses on devising a solution that ensures equitable workload distribution among service providers. Central to this endeavor is the clustering of municipal waste collection points into sectors, fostering a balanced utilization of the fleet across the city.{{newline}}Drawing on principles of sustainable development, the optimization problem revolves around determining how to cluster collection points to promote equitable resource utilization and minimize environmental impact. By achieving uniform fleet consumption and mitigating greenhouse gas emissions, the proposed approach contributes to the broader goal of reducing environmental harm associated with internal combustion vehicles.{{newline}}The Mixed Integer Linear Programming (MILP) was used as the research methodology. The study emphasizes the creation of clusters aligned with specified criteria, facilitating optimal fleet management. Computational experiments utilizing real-world data from the Tarnów Municipality validate the efficacy of the proposed model.;Katarzyna%Gdowska%AGH University of Krakow%Poland%kgdowska@agh.edu.plˇMartyna%Zaucha%AGH University of Krakow%Poland%mzaucha@student.agh.edu.pl
82;Ece Yağmur;The Economic Effect of Advanced Delivery Locations for the Last Mile Routing Problem;https://easychair.org/conferences/submission_view?a=32726078&submission=6884291;ecyagmur@ktun.edu.tr;vehicle routing,home delivery,advanced delivery locations,last mile logistics,mixed integer programming;The last-mile logistics phase is considered the most costly phase in the supply chain. So, some innovative delivery options have been proposed for last-mile activities in recent years. In real life, while some customers prefer only home delivery, others prefer to self-pick up their orders for a certain amount of discount from advanced delivery locations that are accessible 24/7. This paper analyzes a novel last-mile routing problem by utilizing lockers. For optimal distribution decisions under the objective of minimizing the weighted sum of total travel and tardiness costs, a new mixed integer programming (MIP) formulation is developed. The proposed model is applied to newly generated test instances, and some sensitivity analyses of selected parameters are investigated. According to the computational results, it is observed that the exact solver CPLEX is quite sensitive to the number of customers and lockers.;Ece%Yağmur%Konya Technical University%Turkey%ecyagmur@ktun.edu.tr